{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggel: Digit Recognizer(MNIST)  by Hyperopt + Data Augmentaion \n",
    "Kaggle Digit recognizer: https://www.kaggle.com/c/digit-recognizer  \n",
    "Hyperopt: https://github.com/hyperopt/hyperopt  \n",
    "\n",
    "### Score: 0.99671\n",
    "* max_evals= 20 (time: 2h 5m)  \n",
    "* data_augmentation (time: 3m 17s) \n",
    "\n",
    "Python 3.6  \n",
    "NVIDIA GTX1060  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T00:25:48.943407Z",
     "start_time": "2018-11-16T00:25:48.909409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver.: 1.11.0\n",
      "keras ver.     :  2.2.2\n",
      "hyperopt ver.  :    0.2\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, rand, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "seed = 123\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "print('tensorflow ver.:',tf.__version__)\n",
    "print('keras ver.     : ', keras.__version__)\n",
    "print('hyperopt ver.  :   ', hyperopt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: MNIST from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T00:25:51.873577Z",
     "start_time": "2018-11-16T00:25:48.944686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35700, 28, 28, 1), (6300, 28, 28, 1)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "label = train.label\n",
    "train = train.drop(['label'], axis=1)\n",
    "train = train.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train, label, test_size=0.15, shuffle=True, random_state=seed)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "\n",
    "[x_train.shape, x_val.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for Hyperopt:  \n",
    "* Mainly each Dropout ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T00:25:51.879608Z",
     "start_time": "2018-11-16T00:25:51.875124Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Dropout_0':        hp.uniform('Dropout_0', 0.0, 0.5),\n",
    "    'Dropout_1':        hp.uniform('Dropout_1', 0.0, 0.5),\n",
    "    'Dropout_2':        hp.uniform('Dropout_2', 0.0, 0.5),\n",
    "    'Dropout_3':        hp.uniform('Dropout_3', 0.0, 0.5),\n",
    "    'Dropout_4':        hp.uniform('Dropout_4', 0.0, 0.5)\n",
    "}\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T00:25:51.981785Z",
     "start_time": "2018-11-16T00:25:51.880981Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "def cnn_model(params):\n",
    "    \n",
    "    initializer = keras.initializers.glorot_uniform(seed=seed)\n",
    "    \n",
    "    model = Sequential() \n",
    "        \n",
    "    model.add(Conv2D(32*2, (5,5), padding='same', activation='relu', kernel_initializer=initializer, input_shape=(28,28,1)))\n",
    "    model.add(Conv2D(32*2, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_0'], seed=seed))\n",
    "    \n",
    "    model.add(Conv2D(64*2, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(64*2, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_1'], seed=seed))\n",
    "    \n",
    "    model.add(Conv2D(128*2, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(128*2, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_2'], seed=seed))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_3'], seed=seed))\n",
    "    model.add(Dense(128, activation = \"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_4'], seed=seed))\n",
    "    \n",
    "    model.add(Dense(10, activation = \"softmax\", kernel_initializer=initializer))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5,verbose=1, cooldown=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    hist = model.fit(x_train, y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=50,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     callbacks=[reduce_lr, early_stopping])\n",
    "    \n",
    "    loss = hist.history['val_loss'][-1]\n",
    "    acc = hist.history['val_acc'][-1]\n",
    "    \n",
    "    global cnt\n",
    "    print(cnt, ': Val loss:', loss, ': Val acc:', acc, '\\n\\n')\n",
    "    cnt += 1\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model, 'hist': hist}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the Hyperparameters & the Best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T02:31:41.874392Z",
     "start_time": "2018-11-16T00:25:51.983373Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 25s 692us/step - loss: 0.2446 - acc: 0.9233 - val_loss: 0.0789 - val_acc: 0.9762\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 17s 484us/step - loss: 0.0747 - acc: 0.9775 - val_loss: 0.0652 - val_acc: 0.9811\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 17s 486us/step - loss: 0.0584 - acc: 0.9826 - val_loss: 0.0393 - val_acc: 0.9879\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 17s 485us/step - loss: 0.0501 - acc: 0.9847 - val_loss: 0.0325 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 17s 485us/step - loss: 0.0414 - acc: 0.9878 - val_loss: 0.0369 - val_acc: 0.9895\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 17s 485us/step - loss: 0.0430 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 17s 488us/step - loss: 0.0256 - acc: 0.9925 - val_loss: 0.0235 - val_acc: 0.9929\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0209 - val_acc: 0.9940\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 17s 486us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0205 - val_acc: 0.9933\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 17s 485us/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0252 - val_acc: 0.9924\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 491us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0237 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 17s 486us/step - loss: 0.0146 - acc: 0.9959 - val_loss: 0.0146 - val_acc: 0.9957\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 17s 487us/step - loss: 0.0119 - acc: 0.9960 - val_loss: 0.0207 - val_acc: 0.9944\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 17s 486us/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0195 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0167 - val_acc: 0.9952\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 17s 486us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0168 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 491us/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0159 - val_acc: 0.9960\n",
      "Epoch 00017: early stopping\n",
      "0 : Val loss: 0.01591937809467449 : Val acc: 0.996031746031746 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 24s 670us/step - loss: 0.2101 - acc: 0.9355 - val_loss: 0.0880 - val_acc: 0.9752\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 491us/step - loss: 0.0685 - acc: 0.9788 - val_loss: 0.0416 - val_acc: 0.9870\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 17s 490us/step - loss: 0.0518 - acc: 0.9843 - val_loss: 0.0390 - val_acc: 0.9878\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 490us/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.1287 - val_acc: 0.9644\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 491us/step - loss: 0.0398 - acc: 0.9881 - val_loss: 0.0404 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 17s 490us/step - loss: 0.0232 - acc: 0.9928 - val_loss: 0.0239 - val_acc: 0.9916\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0289 - val_acc: 0.9924\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0254 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 503us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0389 - val_acc: 0.9890\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0235 - val_acc: 0.9938\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 505us/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0240 - val_acc: 0.9933\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 492us/step - loss: 0.0119 - acc: 0.9963 - val_loss: 0.0216 - val_acc: 0.9946\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.0245 - val_acc: 0.9935\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0277 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0175 - val_acc: 0.9952\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0213 - val_acc: 0.9948\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0172 - val_acc: 0.9959\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0209 - val_acc: 0.9951\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0234 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 492us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9951\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0186 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 22/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0184 - val_acc: 0.9952\n",
      "Epoch 00022: early stopping\n",
      "1 : Val loss: 0.018366625446143436 : Val acc: 0.9952380952380953 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 24s 674us/step - loss: 0.2899 - acc: 0.9114 - val_loss: 0.0764 - val_acc: 0.9776\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0833 - acc: 0.9750 - val_loss: 0.0472 - val_acc: 0.9860\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 497us/step - loss: 0.0620 - acc: 0.9820 - val_loss: 0.0345 - val_acc: 0.9895\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 491us/step - loss: 0.0487 - acc: 0.9857 - val_loss: 0.0356 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0437 - acc: 0.9868 - val_loss: 0.0247 - val_acc: 0.9929\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0394 - acc: 0.9881 - val_loss: 0.0470 - val_acc: 0.9862\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 491us/step - loss: 0.0378 - acc: 0.9888 - val_loss: 0.0361 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0223 - acc: 0.9933 - val_loss: 0.0201 - val_acc: 0.9944\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0182 - acc: 0.9945 - val_loss: 0.0195 - val_acc: 0.9951\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0224 - acc: 0.9933 - val_loss: 0.0259 - val_acc: 0.9930\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0236 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.0165 - val_acc: 0.9956\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0217 - val_acc: 0.9941\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 492us/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0188 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0197 - val_acc: 0.9952\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0145 - val_acc: 0.9962\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0170 - val_acc: 0.9959\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0178 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0182 - val_acc: 0.9957\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0167 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0153 - val_acc: 0.9960\n",
      "Epoch 00021: early stopping\n",
      "2 : Val loss: 0.015297429318057507 : Val acc: 0.996031746031746 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 24s 677us/step - loss: 0.1854 - acc: 0.9433 - val_loss: 0.1768 - val_acc: 0.9408\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0589 - acc: 0.9819 - val_loss: 0.0294 - val_acc: 0.9910\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0483 - acc: 0.9853 - val_loss: 0.0323 - val_acc: 0.9897\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 496us/step - loss: 0.0385 - acc: 0.9882 - val_loss: 0.0342 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 492us/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0282 - val_acc: 0.9930\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.0307 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0427 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0197 - val_acc: 0.9941\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 492us/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0251 - val_acc: 0.9925\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0218 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 497us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0216 - val_acc: 0.9946\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0207 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0178 - val_acc: 0.9952\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0227 - val_acc: 0.9944\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 497us/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0204 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0194 - val_acc: 0.9948\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0211 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0205 - val_acc: 0.9946\n",
      "Epoch 00018: early stopping\n",
      "3 : Val loss: 0.020459847030006275 : Val acc: 0.9946031746031746 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 24s 680us/step - loss: 0.2031 - acc: 0.9359 - val_loss: 0.0962 - val_acc: 0.9733\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0707 - acc: 0.9783 - val_loss: 0.0493 - val_acc: 0.9840\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 492us/step - loss: 0.0513 - acc: 0.9839 - val_loss: 0.0484 - val_acc: 0.9848\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 496us/step - loss: 0.0469 - acc: 0.9857 - val_loss: 0.0440 - val_acc: 0.9870\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0388 - acc: 0.9881 - val_loss: 0.0381 - val_acc: 0.9884\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 497us/step - loss: 0.0335 - acc: 0.9897 - val_loss: 0.0440 - val_acc: 0.9879\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 496us/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.0342 - val_acc: 0.9897\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0272 - acc: 0.9923 - val_loss: 0.0278 - val_acc: 0.9924\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0262 - acc: 0.9923 - val_loss: 0.0278 - val_acc: 0.9911\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 493us/step - loss: 0.0252 - acc: 0.9919 - val_loss: 0.0308 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0293 - val_acc: 0.9902\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0167 - val_acc: 0.9951\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.0180 - val_acc: 0.9951\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0249 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 495us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0132 - val_acc: 0.9959\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0161 - val_acc: 0.9959\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0170 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 494us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0188 - val_acc: 0.9949\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 497us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0169 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 496us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0136 - val_acc: 0.9967\n",
      "Epoch 00020: early stopping\n",
      "4 : Val loss: 0.013626170607541488 : Val acc: 0.9966666666666667 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 25s 695us/step - loss: 0.1831 - acc: 0.9428 - val_loss: 0.0660 - val_acc: 0.9798\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0634 - acc: 0.9801 - val_loss: 0.0449 - val_acc: 0.9859\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0484 - acc: 0.9849 - val_loss: 0.0419 - val_acc: 0.9879\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 502us/step - loss: 0.0411 - acc: 0.9876 - val_loss: 0.0369 - val_acc: 0.9883\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0349 - acc: 0.9884 - val_loss: 0.0344 - val_acc: 0.9895\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0293 - acc: 0.9912 - val_loss: 0.0562 - val_acc: 0.9846\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0315 - acc: 0.9903 - val_loss: 0.0585 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.0224 - val_acc: 0.9940\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0188 - val_acc: 0.9948\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0245 - val_acc: 0.9925\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0339 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0185 - val_acc: 0.9949\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0179 - val_acc: 0.9948\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 504us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0159 - val_acc: 0.9960\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0242 - val_acc: 0.9938\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0252 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0178 - val_acc: 0.9948\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0164 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0171 - val_acc: 0.9959\n",
      "Epoch 00019: early stopping\n",
      "5 : Val loss: 0.017112546817423583 : Val acc: 0.9958730158730159 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 25s 694us/step - loss: 0.2110 - acc: 0.9337 - val_loss: 0.1298 - val_acc: 0.9625\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0730 - acc: 0.9780 - val_loss: 0.0393 - val_acc: 0.9871\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0507 - acc: 0.9839 - val_loss: 0.0434 - val_acc: 0.9868\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0462 - acc: 0.9849 - val_loss: 0.0368 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0374 - acc: 0.9886 - val_loss: 0.0302 - val_acc: 0.9913\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0348 - acc: 0.9894 - val_loss: 0.0288 - val_acc: 0.9913\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0318 - acc: 0.9903 - val_loss: 0.0408 - val_acc: 0.9889\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0296 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0268 - val_acc: 0.9925\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0216 - val_acc: 0.9946\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0278 - val_acc: 0.9932\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0278 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0191 - val_acc: 0.9951\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 505us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0163 - val_acc: 0.9956\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0206 - val_acc: 0.9951\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 498us/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0208 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 500us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0211 - val_acc: 0.9951\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0187 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 00019: early stopping\n",
      "6 : Val loss: 0.01709713718822477 : Val acc: 0.9952380952380953 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 25s 700us/step - loss: 0.2530 - acc: 0.9222 - val_loss: 0.0788 - val_acc: 0.9757\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0760 - acc: 0.9777 - val_loss: 0.0473 - val_acc: 0.9854\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0546 - acc: 0.9834 - val_loss: 0.0324 - val_acc: 0.9898\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0468 - acc: 0.9857 - val_loss: 0.0344 - val_acc: 0.9892\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 499us/step - loss: 0.0428 - acc: 0.9877 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0255 - acc: 0.9926 - val_loss: 0.0258 - val_acc: 0.9924\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0210 - acc: 0.9937 - val_loss: 0.0247 - val_acc: 0.9922\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 19s 518us/step - loss: 0.0237 - acc: 0.9930 - val_loss: 0.0226 - val_acc: 0.9930\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0240 - acc: 0.9927 - val_loss: 0.0255 - val_acc: 0.9933\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0282 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 508us/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0213 - val_acc: 0.9941\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0179 - val_acc: 0.9956\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 503us/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0177 - val_acc: 0.9952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 503us/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0182 - val_acc: 0.9949\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 502us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0251 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0196 - val_acc: 0.9952\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 501us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0180 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 502us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0181 - val_acc: 0.9954\n",
      "Epoch 00018: early stopping\n",
      "7 : Val loss: 0.01814576182998569 : Val acc: 0.9953968253968254 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 25s 710us/step - loss: 0.2292 - acc: 0.9278 - val_loss: 0.0746 - val_acc: 0.9760\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 504us/step - loss: 0.0727 - acc: 0.9775 - val_loss: 0.0554 - val_acc: 0.9844\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0561 - acc: 0.9822 - val_loss: 0.0458 - val_acc: 0.9856\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 504us/step - loss: 0.0482 - acc: 0.9857 - val_loss: 0.0367 - val_acc: 0.9889\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 504us/step - loss: 0.0387 - acc: 0.9884 - val_loss: 0.0369 - val_acc: 0.9895\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0384 - acc: 0.9878 - val_loss: 0.0316 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.0389 - val_acc: 0.9890\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0342 - acc: 0.9897 - val_loss: 0.0288 - val_acc: 0.9916\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0272 - acc: 0.9920 - val_loss: 0.0293 - val_acc: 0.9910\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0283 - acc: 0.9916 - val_loss: 0.0307 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0194 - val_acc: 0.9949\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0185 - val_acc: 0.9948\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0140 - acc: 0.9957 - val_loss: 0.0211 - val_acc: 0.9946\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.0188 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0162 - val_acc: 0.9954\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 505us/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0257 - val_acc: 0.9937\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 504us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0203 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 504us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0196 - val_acc: 0.9951\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0192 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "Epoch 00020: early stopping\n",
      "8 : Val loss: 0.017149052320210825 : Val acc: 0.9952380952380953 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 26s 716us/step - loss: 0.2779 - acc: 0.9139 - val_loss: 0.0762 - val_acc: 0.9778\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 505us/step - loss: 0.0827 - acc: 0.9745 - val_loss: 0.0429 - val_acc: 0.9871\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0603 - acc: 0.9826 - val_loss: 0.0437 - val_acc: 0.9863\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0509 - acc: 0.9846 - val_loss: 0.0378 - val_acc: 0.9886\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0452 - acc: 0.9864 - val_loss: 0.0425 - val_acc: 0.9875\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0398 - acc: 0.9882 - val_loss: 0.0360 - val_acc: 0.9890\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0372 - acc: 0.9882 - val_loss: 0.0269 - val_acc: 0.9919\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0352 - acc: 0.9895 - val_loss: 0.0338 - val_acc: 0.9903\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 506us/step - loss: 0.0346 - acc: 0.9896 - val_loss: 0.0284 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0226 - acc: 0.9934 - val_loss: 0.0194 - val_acc: 0.9935\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 0.0149 - val_acc: 0.9956\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 508us/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0205 - val_acc: 0.9946\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0177 - acc: 0.9948 - val_loss: 0.0209 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0166 - val_acc: 0.9956\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0212 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 507us/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0163 - val_acc: 0.9960\n",
      "Epoch 00016: early stopping\n",
      "9 : Val loss: 0.01629996380493385 : Val acc: 0.996031746031746 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 26s 725us/step - loss: 0.2101 - acc: 0.9348 - val_loss: 0.0726 - val_acc: 0.9790\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0688 - acc: 0.9787 - val_loss: 0.0528 - val_acc: 0.9829\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0529 - acc: 0.9836 - val_loss: 0.0605 - val_acc: 0.9822\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0483 - acc: 0.9851 - val_loss: 0.0286 - val_acc: 0.9906\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0370 - acc: 0.9892 - val_loss: 0.0433 - val_acc: 0.9860\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.0623 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0324 - val_acc: 0.9917\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0208 - acc: 0.9940 - val_loss: 0.0201 - val_acc: 0.9943\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0231 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0271 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 508us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0189 - val_acc: 0.9949\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 508us/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0193 - val_acc: 0.9944\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0183 - val_acc: 0.9946\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0184 - val_acc: 0.9949\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 508us/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0195 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0146 - val_acc: 0.9959\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0174 - val_acc: 0.9952\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0181 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0168 - val_acc: 0.9957\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0162 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0158 - val_acc: 0.9960\n",
      "Epoch 00021: early stopping\n",
      "10 : Val loss: 0.01578753410013474 : Val acc: 0.996031746031746 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 26s 734us/step - loss: 0.1647 - acc: 0.9485 - val_loss: 0.0700 - val_acc: 0.9771\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0578 - acc: 0.9818 - val_loss: 0.0575 - val_acc: 0.9829\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0454 - acc: 0.9864 - val_loss: 0.0397 - val_acc: 0.9886\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0392 - acc: 0.9878 - val_loss: 0.0402 - val_acc: 0.9900\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.0339 - val_acc: 0.9883\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0324 - acc: 0.9897 - val_loss: 0.0400 - val_acc: 0.9871\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 509us/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.0235 - val_acc: 0.9924\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0260 - acc: 0.9922 - val_loss: 0.0250 - val_acc: 0.9938\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0233 - acc: 0.9924 - val_loss: 0.0266 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0184 - val_acc: 0.9948\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0159 - val_acc: 0.9956\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0227 - val_acc: 0.9932\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0178 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0160 - val_acc: 0.9952\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0171 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0136 - val_acc: 0.9962\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0169 - val_acc: 0.9956\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 518us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0195 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0150 - val_acc: 0.9965\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 9.9199e-04 - acc: 0.9997 - val_loss: 0.0154 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 22/50\n",
      "35700/35700 [==============================] - 18s 510us/step - loss: 8.5683e-04 - acc: 0.9998 - val_loss: 0.0159 - val_acc: 0.9965\n",
      "Epoch 00022: early stopping\n",
      "11 : Val loss: 0.015877100242604872 : Val acc: 0.9965079365079365 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 26s 737us/step - loss: 0.2087 - acc: 0.9338 - val_loss: 0.0672 - val_acc: 0.9765\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0709 - acc: 0.9780 - val_loss: 0.0513 - val_acc: 0.9837\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0526 - acc: 0.9835 - val_loss: 0.0430 - val_acc: 0.9863\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0291 - val_acc: 0.9921\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0385 - acc: 0.9878 - val_loss: 0.0372 - val_acc: 0.9890\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0358 - acc: 0.9890 - val_loss: 0.0324 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0238 - acc: 0.9926 - val_loss: 0.0185 - val_acc: 0.9941\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0186 - val_acc: 0.9946\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0205 - acc: 0.9939 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0133 - acc: 0.9958 - val_loss: 0.0164 - val_acc: 0.9959\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 511us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0194 - val_acc: 0.9948\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 512us/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0202 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0146 - val_acc: 0.9962\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0145 - val_acc: 0.9954\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 19s 531us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0156 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0163 - val_acc: 0.9959\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0147 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0137 - val_acc: 0.9962\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0139 - val_acc: 0.9960\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0145 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0147 - val_acc: 0.9960\n",
      "Epoch 22/50\n",
      "35700/35700 [==============================] - 18s 514us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0143 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 23/50\n",
      "35700/35700 [==============================] - 18s 513us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0143 - val_acc: 0.9960\n",
      "Epoch 00023: early stopping\n",
      "12 : Val loss: 0.014300214854625262 : Val acc: 0.996031746031746 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 27s 748us/step - loss: 0.1984 - acc: 0.9381 - val_loss: 0.0597 - val_acc: 0.9817\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0643 - acc: 0.9794 - val_loss: 0.0441 - val_acc: 0.9859\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0526 - acc: 0.9834 - val_loss: 0.0646 - val_acc: 0.9805\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0383 - acc: 0.9880 - val_loss: 0.0366 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0383 - acc: 0.9879 - val_loss: 0.0476 - val_acc: 0.9863\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0349 - acc: 0.9888 - val_loss: 0.0279 - val_acc: 0.9914\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0345 - acc: 0.9893 - val_loss: 0.0324 - val_acc: 0.9906\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0291 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0202 - val_acc: 0.9933\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0154 - acc: 0.9954 - val_loss: 0.0227 - val_acc: 0.9937\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0169 - val_acc: 0.9957\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0226 - val_acc: 0.9941\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0223 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0157 - val_acc: 0.9956\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0168 - val_acc: 0.9948\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0174 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 518us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0172 - val_acc: 0.9957\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0179 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0169 - val_acc: 0.9963\n",
      "Epoch 00019: early stopping\n",
      "13 : Val loss: 0.016895803819088975 : Val acc: 0.9963492063492063 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 27s 754us/step - loss: 0.2877 - acc: 0.9114 - val_loss: 0.1035 - val_acc: 0.9684\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0791 - acc: 0.9767 - val_loss: 0.0536 - val_acc: 0.9829\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0632 - acc: 0.9809 - val_loss: 0.0738 - val_acc: 0.9786\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0500 - acc: 0.9852 - val_loss: 0.0462 - val_acc: 0.9876\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0459 - acc: 0.9862 - val_loss: 0.0399 - val_acc: 0.9883\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0428 - acc: 0.9872 - val_loss: 0.0365 - val_acc: 0.9910\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0401 - acc: 0.9883 - val_loss: 0.0330 - val_acc: 0.9902\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0380 - acc: 0.9890 - val_loss: 0.0344 - val_acc: 0.9911\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 19s 518us/step - loss: 0.0341 - acc: 0.9899 - val_loss: 0.0381 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0221 - acc: 0.9931 - val_loss: 0.0175 - val_acc: 0.9946\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0191 - acc: 0.9946 - val_loss: 0.0158 - val_acc: 0.9957\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0171 - acc: 0.9948 - val_loss: 0.0181 - val_acc: 0.9944\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0154 - acc: 0.9955 - val_loss: 0.0223 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 18s 518us/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0184 - val_acc: 0.9949\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 18s 518us/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0148 - val_acc: 0.9963\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 18s 517us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0144 - val_acc: 0.9960\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0160 - val_acc: 0.9960\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0145 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0143 - val_acc: 0.9965\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 18s 515us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0154 - val_acc: 0.9963\n",
      "Epoch 22/50\n",
      "35700/35700 [==============================] - 18s 518us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0150 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/50\n",
      "35700/35700 [==============================] - 18s 516us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0148 - val_acc: 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "35700/35700 [==============================] - 18s 518us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0156 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 25/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0152 - val_acc: 0.9965\n",
      "Epoch 00025: early stopping\n",
      "14 : Val loss: 0.01518195620736122 : Val acc: 0.9965079365079365 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 27s 763us/step - loss: 0.1509 - acc: 0.9543 - val_loss: 0.0606 - val_acc: 0.9806\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0564 - acc: 0.9833 - val_loss: 0.0740 - val_acc: 0.9778\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0424 - acc: 0.9871 - val_loss: 0.0342 - val_acc: 0.9895\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 19s 522us/step - loss: 0.0368 - acc: 0.9890 - val_loss: 0.0352 - val_acc: 0.9902\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0323 - acc: 0.9904 - val_loss: 0.0333 - val_acc: 0.9887\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 19s 524us/step - loss: 0.0273 - acc: 0.9921 - val_loss: 0.0364 - val_acc: 0.9894\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 0.0288 - val_acc: 0.9922\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0354 - val_acc: 0.9906\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 19s 523us/step - loss: 0.0224 - acc: 0.9931 - val_loss: 0.0356 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0203 - val_acc: 0.9933\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0220 - val_acc: 0.9948\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0298 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0201 - val_acc: 0.9949\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0211 - val_acc: 0.9952\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0255 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0232 - val_acc: 0.9948\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 7.9232e-04 - acc: 0.9999 - val_loss: 0.0173 - val_acc: 0.9960\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 19s 518us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0201 - val_acc: 0.9954\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0188 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 6.0700e-04 - acc: 0.9999 - val_loss: 0.0176 - val_acc: 0.9959\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 4.1480e-04 - acc: 0.9999 - val_loss: 0.0166 - val_acc: 0.9959\n",
      "Epoch 22/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 4.0569e-04 - acc: 0.9999 - val_loss: 0.0181 - val_acc: 0.9957\n",
      "Epoch 23/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 3.1112e-04 - acc: 0.9999 - val_loss: 0.0190 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 24/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 2.6851e-04 - acc: 0.9999 - val_loss: 0.0194 - val_acc: 0.9952\n",
      "Epoch 25/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 3.9458e-04 - acc: 0.9999 - val_loss: 0.0192 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 26/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 1.9620e-04 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 0.9956\n",
      "Epoch 00026: early stopping\n",
      "15 : Val loss: 0.01917206963649877 : Val acc: 0.9955555555555555 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 27s 769us/step - loss: 0.2306 - acc: 0.9280 - val_loss: 0.0786 - val_acc: 0.9776\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0685 - acc: 0.9792 - val_loss: 0.0435 - val_acc: 0.9870\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 19s 523us/step - loss: 0.0539 - acc: 0.9844 - val_loss: 0.0655 - val_acc: 0.9805\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 19s 523us/step - loss: 0.0494 - acc: 0.9852 - val_loss: 0.0689 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0311 - acc: 0.9906 - val_loss: 0.0242 - val_acc: 0.9922\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.0229 - val_acc: 0.9933\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0258 - acc: 0.9917 - val_loss: 0.0291 - val_acc: 0.9913\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 19s 524us/step - loss: 0.0243 - acc: 0.9926 - val_loss: 0.0289 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0162 - acc: 0.9950 - val_loss: 0.0188 - val_acc: 0.9937\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0211 - val_acc: 0.9930\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 19s 523us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0220 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 19s 522us/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0156 - val_acc: 0.9957\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0153 - val_acc: 0.9959\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 19s 523us/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0182 - val_acc: 0.9949\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 19s 519us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0175 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0166 - val_acc: 0.9957\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0156 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 19s 518us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0145 - val_acc: 0.9960\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 19s 521us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 19s 520us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0146 - val_acc: 0.9967\n",
      "Epoch 22/50\n",
      "35700/35700 [==============================] - 19s 522us/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0164 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 23/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0142 - val_acc: 0.9963\n",
      "Epoch 24/50\n",
      "35700/35700 [==============================] - 19s 522us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0146 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 25/50\n",
      "35700/35700 [==============================] - 19s 524us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0146 - val_acc: 0.9962\n",
      "Epoch 00025: early stopping\n",
      "16 : Val loss: 0.014580558669145425 : Val acc: 0.9961904761904762 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 28s 778us/step - loss: 0.1655 - acc: 0.9483 - val_loss: 0.0467 - val_acc: 0.9851\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 19s 522us/step - loss: 0.0574 - acc: 0.9824 - val_loss: 0.0557 - val_acc: 0.9827\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 19s 524us/step - loss: 0.0440 - acc: 0.9861 - val_loss: 0.1030 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0201 - val_acc: 0.9948\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0210 - acc: 0.9937 - val_loss: 0.0326 - val_acc: 0.9895\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 19s 527us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0291 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0170 - val_acc: 0.9949\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 19s 527us/step - loss: 0.0099 - acc: 0.9968 - val_loss: 0.0199 - val_acc: 0.9949\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0183 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0188 - val_acc: 0.9952\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0192 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 19s 527us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0187 - val_acc: 0.9949\n",
      "Epoch 00012: early stopping\n",
      "17 : Val loss: 0.01868345985499521 : Val acc: 0.9949206349206349 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 28s 782us/step - loss: 0.2079 - acc: 0.9341 - val_loss: 0.0965 - val_acc: 0.9684\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 19s 527us/step - loss: 0.0667 - acc: 0.9791 - val_loss: 0.0382 - val_acc: 0.9886\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0535 - acc: 0.9838 - val_loss: 0.0478 - val_acc: 0.9848\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 19s 527us/step - loss: 0.0415 - acc: 0.9869 - val_loss: 0.0339 - val_acc: 0.9895\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0383 - acc: 0.9880 - val_loss: 0.0262 - val_acc: 0.9917\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 19s 533us/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0308 - val_acc: 0.9913\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0341 - acc: 0.9895 - val_loss: 0.0204 - val_acc: 0.9944\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0286 - acc: 0.9909 - val_loss: 0.0259 - val_acc: 0.9919\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0298 - acc: 0.9907 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0211 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0141 - val_acc: 0.9960\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0147 - val_acc: 0.9965\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 19s 525us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0192 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0168 - val_acc: 0.9954\n",
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0155 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 19s 529us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0144 - val_acc: 0.9957\n",
      "Epoch 00017: early stopping\n",
      "18 : Val loss: 0.014397014892532579 : Val acc: 0.9957142857142857 \n",
      "\n",
      "\n",
      "Train on 35700 samples, validate on 6300 samples\n",
      "Epoch 1/50\n",
      "35700/35700 [==============================] - 28s 792us/step - loss: 0.2354 - acc: 0.9259 - val_loss: 0.0650 - val_acc: 0.9814\n",
      "Epoch 2/50\n",
      "35700/35700 [==============================] - 19s 526us/step - loss: 0.0779 - acc: 0.9761 - val_loss: 0.0603 - val_acc: 0.9817\n",
      "Epoch 3/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0541 - acc: 0.9838 - val_loss: 0.0343 - val_acc: 0.9897\n",
      "Epoch 4/50\n",
      "35700/35700 [==============================] - 19s 529us/step - loss: 0.0488 - acc: 0.9849 - val_loss: 0.0428 - val_acc: 0.9865\n",
      "Epoch 5/50\n",
      "35700/35700 [==============================] - 19s 529us/step - loss: 0.0410 - acc: 0.9877 - val_loss: 0.0365 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.0182 - val_acc: 0.9940\n",
      "Epoch 7/50\n",
      "35700/35700 [==============================] - 19s 532us/step - loss: 0.0224 - acc: 0.9925 - val_loss: 0.0244 - val_acc: 0.9917\n",
      "Epoch 8/50\n",
      "35700/35700 [==============================] - 19s 532us/step - loss: 0.0205 - acc: 0.9936 - val_loss: 0.0326 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0154 - acc: 0.9952 - val_loss: 0.0210 - val_acc: 0.9938\n",
      "Epoch 10/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0134 - acc: 0.9958 - val_loss: 0.0172 - val_acc: 0.9948\n",
      "Epoch 11/50\n",
      "35700/35700 [==============================] - 19s 529us/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0215 - val_acc: 0.9930\n",
      "Epoch 12/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0255 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/50\n",
      "35700/35700 [==============================] - 19s 530us/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 14/50\n",
      "35700/35700 [==============================] - 19s 530us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0186 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/50\n",
      "35700/35700 [==============================] - 19s 528us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0151 - val_acc: 0.9957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "35700/35700 [==============================] - 19s 533us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0130 - val_acc: 0.9960\n",
      "Epoch 17/50\n",
      "35700/35700 [==============================] - 19s 533us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0151 - val_acc: 0.9960\n",
      "Epoch 18/50\n",
      "35700/35700 [==============================] - 19s 531us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0169 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 19/50\n",
      "35700/35700 [==============================] - 19s 533us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0154 - val_acc: 0.9956\n",
      "Epoch 20/50\n",
      "35700/35700 [==============================] - 19s 535us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0146 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 21/50\n",
      "35700/35700 [==============================] - 19s 533us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0145 - val_acc: 0.9960\n",
      "Epoch 00021: early stopping\n",
      "19 : Val loss: 0.014482729101649649 : Val acc: 0.996031746031746 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Dropout_0': 0.29949679088221454,\n",
       " 'Dropout_1': 0.3191838155900335,\n",
       " 'Dropout_2': 0.20843884641241,\n",
       " 'Dropout_3': 0.17705224022098692,\n",
       " 'Dropout_4': 0.28130745896863774}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=cnn_model, \n",
    "            space=params, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=20, # 50: 5h 15m\n",
    "            trials=trials,\n",
    "            verbose=1,\n",
    "            rstate=np.random.RandomState(seed))\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Best Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T02:31:41.881310Z",
     "start_time": "2018-11-16T02:31:41.875914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dropout_0': 0.29949679088221454,\n",
       " 'Dropout_1': 0.3191838155900335,\n",
       " 'Dropout_2': 0.20843884641241,\n",
       " 'Dropout_3': 0.17705224022098692,\n",
       " 'Dropout_4': 0.28130745896863774}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_eval(params, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T02:31:41.894266Z",
     "start_time": "2018-11-16T02:31:41.883062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hist': <keras.callbacks.History at 0x7f9983136f98>,\n",
       " 'loss': -0.9966666666666667,\n",
       " 'model': <keras.engine.sequential.Sequential at 0x7f9984ed6160>,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T05:18:12.461129Z",
     "start_time": "2018-11-10T05:18:12.454484Z"
    }
   },
   "source": [
    "## The Best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T02:31:41.898668Z",
     "start_time": "2018-11-16T02:31:41.895735Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = trials.best_trial['result']['model']\n",
    "#best_model.save('hyperopt_best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation before Data Augumantation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T02:31:44.156621Z",
     "start_time": "2018-11-16T02:31:41.900106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 2s 357us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013626170573792593, 0.9966666666666667]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = best_model.evaluate(x_val, y_val, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T05:35:31.048683Z",
     "start_time": "2018-11-16T05:30:58.947696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 18s - loss: 0.0181 - acc: 0.9940 - val_loss: 0.0118 - val_acc: 0.9962\n",
      "Epoch 2/50\n",
      " - 18s - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0117 - val_acc: 0.9960\n",
      "Epoch 3/50\n",
      " - 18s - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0119 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 4/50\n",
      " - 18s - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0118 - val_acc: 0.9963\n",
      "Epoch 5/50\n",
      " - 18s - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0118 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Epoch 6/50\n",
      " - 18s - loss: 0.0182 - acc: 0.9943 - val_loss: 0.0118 - val_acc: 0.9962\n",
      "Epoch 7/50\n",
      " - 18s - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0117 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 8/50\n",
      " - 18s - loss: 0.0163 - acc: 0.9949 - val_loss: 0.0116 - val_acc: 0.9963\n",
      "Epoch 9/50\n",
      " - 18s - loss: 0.0176 - acc: 0.9948 - val_loss: 0.0119 - val_acc: 0.9960\n",
      "Epoch 10/50\n",
      " - 18s - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0116 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 11/50\n",
      " - 18s - loss: 0.0171 - acc: 0.9949 - val_loss: 0.0119 - val_acc: 0.9960\n",
      "Epoch 12/50\n",
      " - 18s - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0117 - val_acc: 0.9962\n",
      "Epoch 13/50\n",
      " - 18s - loss: 0.0182 - acc: 0.9949 - val_loss: 0.0119 - val_acc: 0.9960\n",
      "Epoch 14/50\n",
      " - 18s - loss: 0.0169 - acc: 0.9948 - val_loss: 0.0117 - val_acc: 0.9963\n",
      "Epoch 15/50\n",
      " - 18s - loss: 0.0162 - acc: 0.9952 - val_loss: 0.0119 - val_acc: 0.9963\n",
      "Epoch 00015: early stopping\n",
      "Loss_aug:  0.01185273813874653 , Acc_aug:  0.9963492063492063 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.1)\n",
    "\n",
    "datagen.fit(x_train, augment=True, seed=seed)\n",
    "\n",
    "reduce_lr_aug = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "early_stop_aug = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "hist_gen = best_model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), \n",
    "                                    epochs=50, \n",
    "                                    validation_data=(x_val, y_val),\n",
    "                                    steps_per_epoch=x_train.shape[0]//batch_size,\n",
    "                                    callbacks=[reduce_lr_aug, early_stop_aug],\n",
    "                                    verbose=2)\n",
    "\n",
    "loss_aug = hist_gen.history['val_loss'][-1]\n",
    "acc_aug = hist_gen.history['val_acc'][-1]\n",
    "\n",
    "print('Loss_aug: ', loss_aug, ', Acc_aug: ', acc_aug, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation after Data Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T05:35:45.127334Z",
     "start_time": "2018-11-16T05:35:42.892662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 2s 354us/step\n",
      "Before augmentation:  [0.013626170573792593, 0.9966666666666667]\n",
      "After  augmentation:  [0.011852738058484632, 0.9963492063492063]\n"
     ]
    }
   ],
   "source": [
    "score_aug = best_model.evaluate(x_val, y_val, verbose=1)\n",
    "print('Before augmentation: ', score)\n",
    "print('After  augmentation: ', score_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for the Submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T05:36:02.089772Z",
     "start_time": "2018-11-16T05:35:50.914910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 10s 342us/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../test.csv')\n",
    "test_index = test.index\n",
    "test = test.values.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "pred = best_model.predict(test, verbose=1)\n",
    "result = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the Submission csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T05:29:55.067121Z",
     "start_time": "2018-11-16T05:29:54.995677Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': test_index+1, 'Label': result})\n",
    "submission.to_csv('hyperopt_augment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy estimation: comparison with the previous result scored at 0.99671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T05:29:59.362133Z",
     "start_time": "2018-11-16T05:29:59.342560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "prev_cnn = pd.read_csv('hyperopt_augment_submission_99671.csv', index_col=0)\n",
    "res = pd.read_csv('hyperopt_augment_submission.csv', index_col=0)\n",
    "match_num = np.sum(prev_cnn.Label.values == res.Label.values)\n",
    "acc = match_num / len(res) #* 0.99671\n",
    "print('Approx. accuracy: {0:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/8d8c3e18921660f7ce139e73358353d8"
  },
  "gist": {
   "data": {
    "description": "Kaggle: Digital Recognizer(MNIST) by Hyperopt + Data Augment",
    "public": true
   },
   "id": "8d8c3e18921660f7ce139e73358353d8"
  },
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
