{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:45:16.220974Z",
     "start_time": "2018-11-13T12:45:16.189789Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Input, Model, load_model\n",
    "from keras.layers import Dense, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "seed = 123\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:45:18.488514Z",
     "start_time": "2018-11-13T12:45:16.222641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33600, 784), (8400, 784)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "label = train.label\n",
    "train = train.drop(['label'], axis=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train, label, test_size=0.2, shuffle=True, random_state=seed)\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=seed)\n",
    "x_train = x_train.values.astype('float32') / 255.0\n",
    "x_val = x_val.values.astype('float32') / 255.0\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "#x_val = x_test.astype('float32') / 255.0\n",
    "# Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "# Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "[x_train.shape, x_val.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:45:18.493059Z",
     "start_time": "2018-11-13T12:45:18.489976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:45:18.791866Z",
     "start_time": "2018-11-13T12:45:18.494434Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "Y_train = Y_train.astype('int64')\n",
    "Y_test = Y_test.astype('int64')\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=seed)\n",
    "# x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:45:18.888930Z",
     "start_time": "2018-11-13T12:45:18.793175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd5f985b5c0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5f97e5860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:45:18.981727Z",
     "start_time": "2018-11-13T12:45:18.890084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd5f94a2f60>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5f981d4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[3].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:48:24.393660Z",
     "start_time": "2018-11-13T12:45:18.983211Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26880 samples, validate on 6720 samples\n",
      "Epoch 1/50\n",
      "26880/26880 [==============================] - 15s 557us/step - loss: 0.5105 - acc: 0.8444 - val_loss: 0.1176 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11757, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96295, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.51053, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.84438, saving model to ck_acc.hdf5\n",
      "Epoch 2/50\n",
      "26880/26880 [==============================] - 10s 390us/step - loss: 0.1577 - acc: 0.9556 - val_loss: 0.0569 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11757 to 0.05693, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96295 to 0.98214, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.51053 to 0.15772, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00002: acc improved from 0.84438 to 0.95558, saving model to ck_acc.hdf5\n",
      "Epoch 3/50\n",
      "26880/26880 [==============================] - 11s 392us/step - loss: 0.1187 - acc: 0.9663 - val_loss: 0.0411 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05693 to 0.04112, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98214 to 0.98616, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 0.15772 to 0.11866, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00003: acc improved from 0.95558 to 0.96633, saving model to ck_acc.hdf5\n",
      "Epoch 4/50\n",
      "26880/26880 [==============================] - 11s 396us/step - loss: 0.1046 - acc: 0.9701 - val_loss: 0.0436 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04112\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98616\n",
      "\n",
      "Epoch 00004: loss improved from 0.11866 to 0.10459, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00004: acc improved from 0.96633 to 0.97013, saving model to ck_acc.hdf5\n",
      "Epoch 5/50\n",
      "26880/26880 [==============================] - 11s 395us/step - loss: 0.0719 - acc: 0.9804 - val_loss: 0.0457 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04112\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98616\n",
      "\n",
      "Epoch 00005: loss improved from 0.10459 to 0.07189, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00005: acc improved from 0.97013 to 0.98039, saving model to ck_acc.hdf5\n",
      "Epoch 6/50\n",
      "26880/26880 [==============================] - 11s 395us/step - loss: 0.0575 - acc: 0.9836 - val_loss: 0.0303 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04112 to 0.03029, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.98616 to 0.99152, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 0.07189 to 0.05752, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00006: acc improved from 0.98039 to 0.98356, saving model to ck_acc.hdf5\n",
      "Epoch 7/50\n",
      "26880/26880 [==============================] - 11s 395us/step - loss: 0.0523 - acc: 0.9850 - val_loss: 0.0285 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03029 to 0.02846, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99152\n",
      "\n",
      "Epoch 00007: loss improved from 0.05752 to 0.05226, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00007: acc improved from 0.98356 to 0.98501, saving model to ck_acc.hdf5\n",
      "Epoch 8/50\n",
      "26880/26880 [==============================] - 11s 397us/step - loss: 0.0480 - acc: 0.9869 - val_loss: 0.0300 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02846\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99152\n",
      "\n",
      "Epoch 00008: loss improved from 0.05226 to 0.04802, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00008: acc improved from 0.98501 to 0.98694, saving model to ck_acc.hdf5\n",
      "Epoch 9/50\n",
      "26880/26880 [==============================] - 11s 396us/step - loss: 0.0453 - acc: 0.9876 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02846\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99152 to 0.99182, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00009: loss improved from 0.04802 to 0.04528, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00009: acc improved from 0.98694 to 0.98765, saving model to ck_acc.hdf5\n",
      "Epoch 10/50\n",
      "26880/26880 [==============================] - 11s 407us/step - loss: 0.0398 - acc: 0.9898 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02846 to 0.02253, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99182 to 0.99315, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00010: loss improved from 0.04528 to 0.03979, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00010: acc improved from 0.98765 to 0.98981, saving model to ck_acc.hdf5\n",
      "Epoch 11/50\n",
      "26880/26880 [==============================] - 11s 396us/step - loss: 0.0371 - acc: 0.9900 - val_loss: 0.0213 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02253 to 0.02134, saving model to ck_val_loss.hdf5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99315 to 0.99345, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00011: loss improved from 0.03979 to 0.03710, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00011: acc improved from 0.98981 to 0.99003, saving model to ck_acc.hdf5\n",
      "Epoch 12/50\n",
      "26880/26880 [==============================] - 11s 393us/step - loss: 0.0345 - acc: 0.9901 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02134\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.99345 to 0.99390, saving model to ck_val_acc.hdf5\n",
      "\n",
      "Epoch 00012: loss improved from 0.03710 to 0.03449, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00012: acc improved from 0.99003 to 0.99010, saving model to ck_acc.hdf5\n",
      "Epoch 13/50\n",
      "26880/26880 [==============================] - 11s 394us/step - loss: 0.0318 - acc: 0.9917 - val_loss: 0.0224 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02134\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99390\n",
      "\n",
      "Epoch 00013: loss improved from 0.03449 to 0.03185, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00013: acc improved from 0.99010 to 0.99167, saving model to ck_acc.hdf5\n",
      "Epoch 14/50\n",
      "26880/26880 [==============================] - 11s 394us/step - loss: 0.0323 - acc: 0.9910 - val_loss: 0.0223 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02134\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99390\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.03185\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.99167\n",
      "Epoch 15/50\n",
      "26880/26880 [==============================] - 11s 393us/step - loss: 0.0331 - acc: 0.9914 - val_loss: 0.0222 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02134\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99390\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.03185\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.99167\n",
      "Epoch 16/50\n",
      "26880/26880 [==============================] - 11s 393us/step - loss: 0.0302 - acc: 0.9917 - val_loss: 0.0217 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02134\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99390\n",
      "\n",
      "Epoch 00016: loss improved from 0.03185 to 0.03022, saving model to ck_loss.hdf5\n",
      "\n",
      "Epoch 00016: acc improved from 0.99167 to 0.99174, saving model to ck_acc.hdf5\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "initializer = keras.initializers.glorot_uniform(seed=seed)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer=initializer))\n",
    "# model.add(Dropout(0.2, seed=seed))\n",
    "# model.add(Dense(256, activation='relu', kernel_initializer=initializer))\n",
    "# model.add(Dropout(0.2, seed=seed))\n",
    "# model.add(Dense(10, activation='softmax', kernel_initializer=initializer))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((28,28,1), input_shape=(784,)))\n",
    "\n",
    "model.add(Conv2D(32, (5,5),padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(Conv2D(32, (5,5),padding='same', activation='relu', kernel_initializer=initializer))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25, seed=seed))\n",
    "model.add(Conv2D(64, (3,3),padding = 'same', activation ='relu', kernel_initializer=initializer))\n",
    "model.add(Conv2D(64, (3,3),padding = 'same', activation ='relu', kernel_initializer=initializer))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25, seed=seed))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = \"relu\", kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5, seed=seed))\n",
    "model.add(Dense(64, activation = \"relu\", kernel_initializer=initializer))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5, seed=seed))\n",
    "model.add(Dense(10, activation = \"softmax\", kernel_initializer=initializer))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-5,verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "ck_val_loss = ModelCheckpoint(filepath='ck_val_loss.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "ck_val_acc = ModelCheckpoint(filepath='ck_val_acc.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "ck_loss = ModelCheckpoint(filepath='ck_loss.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
    "ck_acc = ModelCheckpoint(filepath='ck_acc.hdf5', monitor='acc', verbose=1, save_best_only=True)\n",
    "\n",
    "hist = model.fit(x_train, \n",
    "                 y_train, \n",
    "                 epochs=50, \n",
    "                 batch_size=32,\n",
    "                 validation_split=0.2,\n",
    "                 #validation_data=(x_val, y_val),\n",
    "                 #shuffle=False,\n",
    "                 verbose=1, \n",
    "                 callbacks=[reduce_lr, early_stopping, ck_val_loss, ck_val_acc, ck_loss, ck_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:50:02.068149Z",
     "start_time": "2018-11-13T12:48:24.395688Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 185us/step\n",
      "60000/60000 [==============================] - 11s 189us/step\n",
      "60000/60000 [==============================] - 11s 187us/step\n",
      "60000/60000 [==============================] - 11s 190us/step\n",
      "60000/60000 [==============================] - 9s 158us/step\n"
     ]
    }
   ],
   "source": [
    "val_loss_model = load_model('ck_val_loss.hdf5')\n",
    "val_acc_model = load_model('ck_val_acc.hdf5')\n",
    "loss_model = load_model('ck_loss.hdf5')\n",
    "acc_model = load_model('ck_acc.hdf5')\n",
    "\n",
    "# val_loss_res = val_loss_model.evaluate(x_val, y_val, verbose=1)\n",
    "# val_acc_res = val_acc_model.evaluate(x_val, y_val, verbose=1)\n",
    "# loss_res = loss_model.evaluate(x_val, y_val, verbose=1)\n",
    "# acc_res = acc_model.evaluate(x_val, y_val, verbose=1)\n",
    "# res = model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "val_loss_res = val_loss_model.evaluate(X_train, Y_train, verbose=1)\n",
    "val_acc_res = val_acc_model.evaluate(X_train, Y_train, verbose=1)\n",
    "loss_res = loss_model.evaluate(X_train, Y_train, verbose=1)\n",
    "acc_res = acc_model.evaluate(X_train, Y_train, verbose=1)\n",
    "res = model.evaluate(X_train, Y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:50:02.076031Z",
     "start_time": "2018-11-13T12:50:02.069470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.01793745 0.9947666666666667\n",
      " val_acc: 0.01803323 0.9950333333333333\n",
      "    loss: 0.01702244 0.9951333333333333\n",
      "     acc: 0.01702244 0.9951333333333333\n",
      "     res: 0.01702244 0.9951333333333333\n",
      "    hist: 0.02133617 0.9938988095238095\n"
     ]
    }
   ],
   "source": [
    "print('val_loss:', '{0:.8f}'.format(val_loss_res[0]), val_loss_res[1])#:\n",
    "print(' val_acc:', '{0:.8f}'.format(val_acc_res[0]), val_acc_res[1])  #:\n",
    "print('    loss:', '{0:.8f}'.format(loss_res[0]), loss_res[1])        #:1\n",
    "print('     acc:', '{0:.8f}'.format(acc_res[0]), acc_res[1])          #:1\n",
    "print('     res:', '{0:.8f}'.format(res[0]), res[1])                  #:\n",
    "print('    hist:', '{0:.8f}'.format(np.min(hist.history['val_loss'])), np.max(hist.history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:54:19.398861Z",
     "start_time": "2018-11-13T12:54:17.874780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 152us/step\n"
     ]
    }
   ],
   "source": [
    "pred1 = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:55:02.987574Z",
     "start_time": "2018-11-13T12:55:02.980192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = pred1.argmax(axis=1)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T13:00:54.138976Z",
     "start_time": "2018-11-13T13:00:48.624197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 4s 150us/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../test.csv')\n",
    "test_index = test.index\n",
    "test = test.values.astype('float32') / 255.0\n",
    "\n",
    "pred = model.predict(test, verbose=1)\n",
    "result = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T13:00:57.967379Z",
     "start_time": "2018-11-13T13:00:57.902620Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': test_index+1, 'Label': result})\n",
    "submission.to_csv('comp_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T13:01:00.612642Z",
     "start_time": "2018-11-13T13:01:00.596105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. accuracy: 0.99393\n"
     ]
    }
   ],
   "source": [
    "prev_cnn = pd.read_csv('../cnn_submission.csv', index_col=0)\n",
    "res = pd.read_csv('comp_submission.csv', index_col=0)\n",
    "diff_num = np.sum(prev_cnn.Label.values != res.Label.values)\n",
    "acc = (len(res) - diff_num) / len(res) * 0.998276\n",
    "print('Approx. accuracy: {0:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:58:53.950979Z",
     "start_time": "2018-11-13T12:58:53.944272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  10,  17,  17,  17,  17,  81, 180, 180,\n",
       "        35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 253, 253, 253, 253,\n",
       "       253, 253,  48,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  60, 228, 253, 253, 253,\n",
       "       253, 253, 253, 253, 207, 197,  46,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 213, 253, 253,\n",
       "       253, 253, 253, 253, 253, 253, 253, 253, 223,  52,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66,\n",
       "       231, 253, 253, 253, 108,  40,  40, 115, 244, 253, 253, 134,   3,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  63, 114, 114, 114,  37,   0,   0,   0, 205, 253, 253,\n",
       "       253,  15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  57,\n",
       "       253, 253, 253,  15,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  42, 253, 253, 253,  15,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  95, 253, 253, 253,  15,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 205, 253, 253, 253,  15,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  61,  99,  96,   0,   0,  45, 224, 253, 253, 195,  10,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,  25, 105,\n",
       "        83, 189, 189, 228, 253, 251, 189, 189, 218, 253, 253, 210,  27,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 116, 173,\n",
       "       253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253,\n",
       "       221, 116,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0, 118,\n",
       "       253, 253, 253, 253, 245, 212, 222, 253, 253, 253, 253, 253, 253,\n",
       "       253, 253, 253, 253, 160,  15,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 254, 253, 253, 253, 189,  99,   0,  32, 202, 253, 253, 253,\n",
       "       240, 122, 122, 190, 253, 253, 253, 174,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 255, 253, 253, 253, 238, 222, 222, 222, 241, 253,\n",
       "       253, 230,  70,   0,   0,  17, 175, 229, 253, 253,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 158, 253, 253, 253, 253, 253, 253, 253,\n",
       "       253, 205, 106,  65,   0,   0,   0,   0,   0,  62, 244, 157,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   6,  26, 179, 179, 179, 179,\n",
       "       179,  30,  15,  10,   0,   0,   0,   0,   0,   0,   0,   0,  14,\n",
       "         6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:50:24.374720Z",
     "start_time": "2018-11-13T12:50:24.371568Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_loss: 0.01749513 0.9945\n",
    "#  val_acc: 0.01761668 0.9944\n",
    "#     loss: 0.01749513 0.9945\n",
    "#      acc: 0.01749513 0.9945\n",
    "#      res: 0.01726679 0.9947\n",
    "#     hist: 0.02747315 0.9933333333333333\n",
    "\n",
    "# val_loss: 0.01986853 0.9939\n",
    "#  val_acc: 0.02089765 0.9943\n",
    "#     loss: 0.02874065 0.9924\n",
    "#      acc: 0.02874065 0.9924\n",
    "#      res: 0.02874065 0.9924\n",
    "#     hist: 0.03196515 0.9915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:50:24.379218Z",
     "start_time": "2018-11-13T12:50:24.376146Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(hist.history['acc'], 'b-', label='Acc' )\n",
    "# plt.plot(hist.history['loss'], 'r-', label='Loss' )\n",
    "# plt.xlabel('epochs')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T12:50:24.385311Z",
     "start_time": "2018-11-13T12:50:24.380551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
