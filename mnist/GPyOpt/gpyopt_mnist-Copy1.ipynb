{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggel: Digit Recognizer(MNIST)  by Hyperopt  \n",
    "Kaggle Digit recognizer: https://www.kaggle.com/c/digit-recognizer  \n",
    "GPyOpt: https://github.com/SheffieldML/GPyOpt  \n",
    "\n",
    "### Score:\n",
    "* max_evals= 10, score: -- ( -- mins: NVIDIA GTX1060)\n",
    "* max_evals= 20, score: -- ( -- mins: NVIDIA GTX1060)\n",
    "* max_evals=100, score: -- ( -- mins: NVIDIA GTX1060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:05:43.437659Z",
     "start_time": "2018-11-12T04:05:43.404906Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "seed = 123\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: MNIST from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:05:45.954698Z",
     "start_time": "2018-11-12T04:05:43.439078Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "label = train.label\n",
    "train = train.drop(['label'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train, label, test_size=0.2, shuffle=True, random_state=seed)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:05:45.962801Z",
     "start_time": "2018-11-12T04:05:45.955916Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'name': 'Dropout_0',        'type': 'continuous',  'domain': (0.0, 1.0)},\n",
    "    {'name': 'Dropout_1',        'type': 'continuous',  'domain': (0.0, 1.0)},\n",
    "    {'name': 'Dropout_2',        'type': 'continuous',  'domain': (0.0, 1.0)},\n",
    "    {'name': 'Dropout_3',        'type': 'continuous',  'domain': (0.0, 1.0)},\n",
    "    #{'name': 'BatchNorm_0',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    #{'name': 'BatchNorm_1',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    #{'name': 'BatchNorm_2',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    #{'name': 'BatchNorm_3',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    {'name': 'Dense_0',          'type': 'discrete',    'domain': (256, 512)},\n",
    "    {'name': 'Dense_1',          'type': 'discrete',    'domain': (128, 256)},\n",
    "    {'name': 'validation_split', 'type': 'continuous',  'domain': (0.1, 0.3)},\n",
    "    {'name': 'batch_size',       'type': 'discrete',    'domain': (8, 16, 32)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:05:45.975214Z",
     "start_time": "2018-11-12T04:05:45.963998Z"
    }
   },
   "outputs": [],
   "source": [
    "# def param(p_name):\n",
    "#     index = [p['name'] for p in params].index(p_name)\n",
    "#     return params[index]\n",
    "\n",
    "# param('Dropout_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:05:46.109145Z",
     "start_time": "2018-11-12T04:05:45.977019Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "def cnn_model(x):\n",
    "    \n",
    "    def Param(p_name):\n",
    "        p_index = [p['name'] for p in params].index(p_name)\n",
    "        p_type = params[p_index]['type']\n",
    "        if p_type == 'continuous':\n",
    "            return float(x[:, p_index])\n",
    "        else:\n",
    "            return int(x[:, p_index])\n",
    "    \n",
    "    initializer = keras.initializers.glorot_uniform(seed=seed)\n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(Reshape((28,28,1), input_shape=(784,)))\n",
    "        \n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_0'), seed=seed))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_1'), seed=seed))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(Param('Dense_0'), activation=\"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_2'), seed=seed))\n",
    "    model.add(Dense(Param('Dense_1'), activation = \"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_3'), seed=seed))\n",
    "    \n",
    "    model.add(Dense(10, activation = \"softmax\", kernel_initializer=initializer))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=1e-5,verbose=1, cooldown=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "    #checkpointer = ModelCheckpoint(filepath='checkpoint'+str(cnt)+'.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    hist = model.fit(X_train, Y_train,\n",
    "                     batch_size=Param('batch_size'),\n",
    "                     epochs=50,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     validation_split=Param('validation_split'),\n",
    "                     callbacks=[reduce_lr, early_stopping])\n",
    "    \n",
    "    #loss, acc = model.evaluate(X_test, Y_test, batch_size=32 , verbose=0)\n",
    "    val_loss = hist.history['val_loss'][-1]\n",
    "    val_acc = hist.history['val_acc'][-1]\n",
    "    \n",
    "    global cnt\n",
    "    print(cnt, ': Val_loss:',val_loss, ', Val_acc:', val_acc)\n",
    "    cnt += 1\n",
    "    #return {'loss': loss, 'acc': acc,  'model': model, 'hist': hist}\n",
    "    #return val_loss, val_acc, model, hist\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:40:37.870667Z",
     "start_time": "2018-11-12T04:05:46.110909Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28266 samples, validate on 5334 samples\n",
      "Epoch 1/50\n",
      "28266/28266 [==============================] - 21s 741us/step - loss: 0.4898 - acc: 0.8516 - val_loss: 0.0767 - val_acc: 0.9764\n",
      "Epoch 2/50\n",
      "28266/28266 [==============================] - 18s 649us/step - loss: 0.1886 - acc: 0.9453 - val_loss: 0.0568 - val_acc: 0.9807\n",
      "Epoch 3/50\n",
      "28266/28266 [==============================] - 18s 646us/step - loss: 0.1489 - acc: 0.9574 - val_loss: 0.0522 - val_acc: 0.9844\n",
      "Epoch 4/50\n",
      "28266/28266 [==============================] - 18s 646us/step - loss: 0.1248 - acc: 0.9642 - val_loss: 0.0522 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 5/50\n",
      "28266/28266 [==============================] - 18s 647us/step - loss: 0.0865 - acc: 0.9755 - val_loss: 0.0338 - val_acc: 0.9910\n",
      "Epoch 6/50\n",
      "28266/28266 [==============================] - 18s 647us/step - loss: 0.0714 - acc: 0.9797 - val_loss: 0.0329 - val_acc: 0.9899\n",
      "Epoch 7/50\n",
      "28266/28266 [==============================] - 19s 659us/step - loss: 0.0655 - acc: 0.9819 - val_loss: 0.0316 - val_acc: 0.9910\n",
      "Epoch 8/50\n",
      "28266/28266 [==============================] - 18s 648us/step - loss: 0.0604 - acc: 0.9830 - val_loss: 0.0279 - val_acc: 0.9916\n",
      "Epoch 9/50\n",
      "28266/28266 [==============================] - 18s 646us/step - loss: 0.0556 - acc: 0.9843 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 10/50\n",
      "28266/28266 [==============================] - 19s 658us/step - loss: 0.0470 - acc: 0.9867 - val_loss: 0.0274 - val_acc: 0.9934\n",
      "Epoch 11/50\n",
      "28266/28266 [==============================] - 19s 658us/step - loss: 0.0433 - acc: 0.9882 - val_loss: 0.0266 - val_acc: 0.9929\n",
      "Epoch 12/50\n",
      "28266/28266 [==============================] - 19s 657us/step - loss: 0.0438 - acc: 0.9869 - val_loss: 0.0261 - val_acc: 0.9933\n",
      "Epoch 13/50\n",
      "28266/28266 [==============================] - 18s 641us/step - loss: 0.0396 - acc: 0.9890 - val_loss: 0.0287 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 14/50\n",
      "28266/28266 [==============================] - 18s 642us/step - loss: 0.0410 - acc: 0.9882 - val_loss: 0.0260 - val_acc: 0.9931\n",
      "Epoch 15/50\n",
      "28266/28266 [==============================] - 18s 644us/step - loss: 0.0391 - acc: 0.9889 - val_loss: 0.0272 - val_acc: 0.9929\n",
      "Epoch 16/50\n",
      "28266/28266 [==============================] - 18s 643us/step - loss: 0.0431 - acc: 0.9881 - val_loss: 0.0274 - val_acc: 0.9931\n",
      "Epoch 17/50\n",
      "28266/28266 [==============================] - 18s 644us/step - loss: 0.0397 - acc: 0.9885 - val_loss: 0.0250 - val_acc: 0.9936\n",
      "Epoch 18/50\n",
      "28266/28266 [==============================] - 18s 647us/step - loss: 0.0374 - acc: 0.9897 - val_loss: 0.0260 - val_acc: 0.9934\n",
      "Epoch 19/50\n",
      "28266/28266 [==============================] - 18s 644us/step - loss: 0.0392 - acc: 0.9889 - val_loss: 0.0257 - val_acc: 0.9934\n",
      "Epoch 20/50\n",
      "28266/28266 [==============================] - 18s 645us/step - loss: 0.0382 - acc: 0.9887 - val_loss: 0.0268 - val_acc: 0.9936\n",
      "Epoch 00020: early stopping\n",
      "0 : Val_loss: 0.026838116568562016 , Val_acc: 0.9936257967754031\n",
      "Train on 25999 samples, validate on 7601 samples\n",
      "Epoch 1/50\n",
      "25999/25999 [==============================] - 14s 531us/step - loss: 0.5982 - acc: 0.8226 - val_loss: 0.0803 - val_acc: 0.9749\n",
      "Epoch 2/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.1884 - acc: 0.9450 - val_loss: 0.0687 - val_acc: 0.9792\n",
      "Epoch 3/50\n",
      "25999/25999 [==============================] - 11s 419us/step - loss: 0.1413 - acc: 0.9593 - val_loss: 0.0496 - val_acc: 0.9846\n",
      "Epoch 4/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.1225 - acc: 0.9652 - val_loss: 0.0486 - val_acc: 0.9826\n",
      "Epoch 5/50\n",
      "25999/25999 [==============================] - 11s 419us/step - loss: 0.1044 - acc: 0.9714 - val_loss: 0.0391 - val_acc: 0.9879\n",
      "Epoch 6/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.0921 - acc: 0.9740 - val_loss: 0.0477 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/50\n",
      "25999/25999 [==============================] - 11s 416us/step - loss: 0.0746 - acc: 0.9795 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "Epoch 8/50\n",
      "25999/25999 [==============================] - 11s 419us/step - loss: 0.0601 - acc: 0.9826 - val_loss: 0.0294 - val_acc: 0.9914\n",
      "Epoch 9/50\n",
      "25999/25999 [==============================] - 11s 417us/step - loss: 0.0525 - acc: 0.9853 - val_loss: 0.0293 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 10/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.0452 - acc: 0.9875 - val_loss: 0.0276 - val_acc: 0.9920\n",
      "Epoch 11/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.0455 - acc: 0.9871 - val_loss: 0.0272 - val_acc: 0.9918\n",
      "Epoch 12/50\n",
      "25999/25999 [==============================] - 11s 419us/step - loss: 0.0434 - acc: 0.9872 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 13/50\n",
      "25999/25999 [==============================] - 11s 417us/step - loss: 0.0447 - acc: 0.9882 - val_loss: 0.0271 - val_acc: 0.9920\n",
      "Epoch 14/50\n",
      "25999/25999 [==============================] - 11s 417us/step - loss: 0.0421 - acc: 0.9885 - val_loss: 0.0269 - val_acc: 0.9921\n",
      "Epoch 15/50\n",
      "25999/25999 [==============================] - 11s 420us/step - loss: 0.0428 - acc: 0.9881 - val_loss: 0.0268 - val_acc: 0.9925\n",
      "Epoch 16/50\n",
      "25999/25999 [==============================] - 11s 425us/step - loss: 0.0402 - acc: 0.9885 - val_loss: 0.0264 - val_acc: 0.9926\n",
      "Epoch 17/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.0417 - acc: 0.9879 - val_loss: 0.0266 - val_acc: 0.9926\n",
      "Epoch 18/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.0408 - acc: 0.9890 - val_loss: 0.0262 - val_acc: 0.9930\n",
      "Epoch 19/50\n",
      "25999/25999 [==============================] - 11s 418us/step - loss: 0.0451 - acc: 0.9875 - val_loss: 0.0260 - val_acc: 0.9928\n",
      "Epoch 20/50\n",
      "25999/25999 [==============================] - 11s 416us/step - loss: 0.0373 - acc: 0.9893 - val_loss: 0.0261 - val_acc: 0.9926\n",
      "Epoch 21/50\n",
      "25999/25999 [==============================] - 11s 416us/step - loss: 0.0406 - acc: 0.9896 - val_loss: 0.0264 - val_acc: 0.9925\n",
      "Epoch 22/50\n",
      "25999/25999 [==============================] - 11s 414us/step - loss: 0.0394 - acc: 0.9889 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "Epoch 00022: early stopping\n",
      "1 : Val_loss: 0.026369394768564158 , Val_acc: 0.9922378634390212\n",
      "Train on 29621 samples, validate on 3979 samples\n",
      "Epoch 1/50\n",
      "29621/29621 [==============================] - 23s 766us/step - loss: 0.5616 - acc: 0.8224 - val_loss: 0.1057 - val_acc: 0.9668\n",
      "Epoch 2/50\n",
      "29621/29621 [==============================] - 20s 669us/step - loss: 0.2081 - acc: 0.9378 - val_loss: 0.0721 - val_acc: 0.9781\n",
      "Epoch 3/50\n",
      "29621/29621 [==============================] - 20s 673us/step - loss: 0.1653 - acc: 0.9493 - val_loss: 0.0588 - val_acc: 0.9809\n",
      "Epoch 4/50\n",
      "29621/29621 [==============================] - 20s 672us/step - loss: 0.1453 - acc: 0.9565 - val_loss: 0.0763 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 5/50\n",
      "29621/29621 [==============================] - 20s 667us/step - loss: 0.1081 - acc: 0.9680 - val_loss: 0.0356 - val_acc: 0.9867\n",
      "Epoch 6/50\n",
      "29621/29621 [==============================] - 20s 670us/step - loss: 0.0882 - acc: 0.9739 - val_loss: 0.0343 - val_acc: 0.9889\n",
      "Epoch 7/50\n",
      "29621/29621 [==============================] - 20s 668us/step - loss: 0.0817 - acc: 0.9763 - val_loss: 0.0363 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 8/50\n",
      "29621/29621 [==============================] - 20s 684us/step - loss: 0.0737 - acc: 0.9779 - val_loss: 0.0315 - val_acc: 0.9892\n",
      "Epoch 9/50\n",
      "29621/29621 [==============================] - 20s 679us/step - loss: 0.0751 - acc: 0.9785 - val_loss: 0.0303 - val_acc: 0.9894\n",
      "Epoch 10/50\n",
      "29621/29621 [==============================] - 20s 677us/step - loss: 0.0712 - acc: 0.9795 - val_loss: 0.0300 - val_acc: 0.9892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "29621/29621 [==============================] - 19s 656us/step - loss: 0.0701 - acc: 0.9781 - val_loss: 0.0297 - val_acc: 0.9892\n",
      "Epoch 12/50\n",
      "29621/29621 [==============================] - 19s 656us/step - loss: 0.0726 - acc: 0.9785 - val_loss: 0.0301 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 13/50\n",
      "29621/29621 [==============================] - 19s 656us/step - loss: 0.0678 - acc: 0.9798 - val_loss: 0.0299 - val_acc: 0.9892\n",
      "Epoch 14/50\n",
      "29621/29621 [==============================] - 19s 657us/step - loss: 0.0658 - acc: 0.9800 - val_loss: 0.0290 - val_acc: 0.9889\n",
      "Epoch 15/50\n",
      "29621/29621 [==============================] - 19s 656us/step - loss: 0.0640 - acc: 0.9803 - val_loss: 0.0302 - val_acc: 0.9892\n",
      "Epoch 16/50\n",
      "29621/29621 [==============================] - 19s 657us/step - loss: 0.0681 - acc: 0.9795 - val_loss: 0.0296 - val_acc: 0.9889\n",
      "Epoch 17/50\n",
      "29621/29621 [==============================] - 20s 662us/step - loss: 0.0677 - acc: 0.9803 - val_loss: 0.0285 - val_acc: 0.9892\n",
      "Epoch 18/50\n",
      "29621/29621 [==============================] - 20s 671us/step - loss: 0.0606 - acc: 0.9815 - val_loss: 0.0286 - val_acc: 0.9894\n",
      "Epoch 19/50\n",
      "29621/29621 [==============================] - 20s 672us/step - loss: 0.0644 - acc: 0.9808 - val_loss: 0.0283 - val_acc: 0.9892\n",
      "Epoch 20/50\n",
      "29621/29621 [==============================] - 20s 671us/step - loss: 0.0638 - acc: 0.9813 - val_loss: 0.0283 - val_acc: 0.9889\n",
      "Epoch 21/50\n",
      "29621/29621 [==============================] - 20s 674us/step - loss: 0.0624 - acc: 0.9809 - val_loss: 0.0287 - val_acc: 0.9894\n",
      "Epoch 22/50\n",
      "29621/29621 [==============================] - 21s 702us/step - loss: 0.0660 - acc: 0.9803 - val_loss: 0.0282 - val_acc: 0.9897\n",
      "Epoch 23/50\n",
      "29621/29621 [==============================] - 20s 679us/step - loss: 0.0620 - acc: 0.9808 - val_loss: 0.0283 - val_acc: 0.9894\n",
      "Epoch 24/50\n",
      "29621/29621 [==============================] - 20s 675us/step - loss: 0.0605 - acc: 0.9820 - val_loss: 0.0282 - val_acc: 0.9894\n",
      "Epoch 25/50\n",
      "29621/29621 [==============================] - 20s 671us/step - loss: 0.0617 - acc: 0.9826 - val_loss: 0.0276 - val_acc: 0.9897\n",
      "Epoch 26/50\n",
      "29621/29621 [==============================] - 20s 672us/step - loss: 0.0621 - acc: 0.9817 - val_loss: 0.0267 - val_acc: 0.9902\n",
      "Epoch 27/50\n",
      "29621/29621 [==============================] - 20s 670us/step - loss: 0.0610 - acc: 0.9815 - val_loss: 0.0278 - val_acc: 0.9897\n",
      "Epoch 28/50\n",
      "29621/29621 [==============================] - 20s 672us/step - loss: 0.0634 - acc: 0.9809 - val_loss: 0.0280 - val_acc: 0.9892\n",
      "Epoch 29/50\n",
      "29621/29621 [==============================] - 20s 669us/step - loss: 0.0610 - acc: 0.9811 - val_loss: 0.0282 - val_acc: 0.9894\n",
      "Epoch 00029: early stopping\n",
      "2 : Val_loss: 0.028198241371597994 , Val_acc: 0.9894445840663483\n",
      "Train on 27325 samples, validate on 6275 samples\n",
      "Epoch 1/50\n",
      "27325/27325 [==============================] - 38s 1ms/step - loss: 0.9974 - acc: 0.6751 - val_loss: 0.1403 - val_acc: 0.9584\n",
      "Epoch 2/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.4403 - acc: 0.8637 - val_loss: 0.0833 - val_acc: 0.9724\n",
      "Epoch 3/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.3533 - acc: 0.8935 - val_loss: 0.1732 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 4/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.2644 - acc: 0.9214 - val_loss: 0.0592 - val_acc: 0.9801\n",
      "Epoch 5/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.2296 - acc: 0.9330 - val_loss: 0.0502 - val_acc: 0.9841\n",
      "Epoch 6/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.2030 - acc: 0.9401 - val_loss: 0.0485 - val_acc: 0.9834\n",
      "Epoch 7/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1920 - acc: 0.9455 - val_loss: 0.0470 - val_acc: 0.9841\n",
      "Epoch 8/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1842 - acc: 0.9471 - val_loss: 0.0457 - val_acc: 0.9844\n",
      "Epoch 9/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1674 - acc: 0.9528 - val_loss: 0.0488 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 10/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1546 - acc: 0.9567 - val_loss: 0.0428 - val_acc: 0.9868\n",
      "Epoch 11/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1565 - acc: 0.9561 - val_loss: 0.0410 - val_acc: 0.9869\n",
      "Epoch 12/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1451 - acc: 0.9593 - val_loss: 0.0413 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 13/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1466 - acc: 0.9607 - val_loss: 0.0394 - val_acc: 0.9874\n",
      "Epoch 14/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1403 - acc: 0.9619 - val_loss: 0.0396 - val_acc: 0.9879\n",
      "Epoch 15/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1468 - acc: 0.9593 - val_loss: 0.0394 - val_acc: 0.9882\n",
      "Epoch 16/50\n",
      "27325/27325 [==============================] - 35s 1ms/step - loss: 0.1427 - acc: 0.9609 - val_loss: 0.0401 - val_acc: 0.9877\n",
      "Epoch 00016: early stopping\n",
      "3 : Val_loss: 0.040059519495315984 , Val_acc: 0.9877290836653386\n",
      "Train on 27344 samples, validate on 6256 samples\n",
      "Epoch 1/50\n",
      "27344/27344 [==============================] - 22s 816us/step - loss: 0.4339 - acc: 0.8636 - val_loss: 0.0889 - val_acc: 0.9707\n",
      "Epoch 2/50\n",
      "27344/27344 [==============================] - 19s 698us/step - loss: 0.1746 - acc: 0.9474 - val_loss: 0.0824 - val_acc: 0.9733\n",
      "Epoch 3/50\n",
      "27344/27344 [==============================] - 19s 701us/step - loss: 0.1451 - acc: 0.9575 - val_loss: 0.0538 - val_acc: 0.9831\n",
      "Epoch 4/50\n",
      "27344/27344 [==============================] - 19s 701us/step - loss: 0.1121 - acc: 0.9676 - val_loss: 0.0416 - val_acc: 0.9861\n",
      "Epoch 5/50\n",
      "27344/27344 [==============================] - 19s 705us/step - loss: 0.1045 - acc: 0.9691 - val_loss: 0.0432 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 6/50\n",
      "27344/27344 [==============================] - 19s 703us/step - loss: 0.0728 - acc: 0.9790 - val_loss: 0.0314 - val_acc: 0.9901\n",
      "Epoch 7/50\n",
      "27344/27344 [==============================] - 19s 701us/step - loss: 0.0588 - acc: 0.9828 - val_loss: 0.0300 - val_acc: 0.9907\n",
      "Epoch 8/50\n",
      "27344/27344 [==============================] - 19s 701us/step - loss: 0.0508 - acc: 0.9853 - val_loss: 0.0268 - val_acc: 0.9910\n",
      "Epoch 9/50\n",
      "27344/27344 [==============================] - 19s 702us/step - loss: 0.0524 - acc: 0.9854 - val_loss: 0.0252 - val_acc: 0.9925\n",
      "Epoch 10/50\n",
      "27344/27344 [==============================] - 19s 704us/step - loss: 0.0459 - acc: 0.9866 - val_loss: 0.0250 - val_acc: 0.9925\n",
      "Epoch 11/50\n",
      "27344/27344 [==============================] - 19s 701us/step - loss: 0.0413 - acc: 0.9872 - val_loss: 0.0261 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 12/50\n",
      "27344/27344 [==============================] - 19s 701us/step - loss: 0.0400 - acc: 0.9880 - val_loss: 0.0245 - val_acc: 0.9925\n",
      "Epoch 13/50\n",
      "27344/27344 [==============================] - 19s 702us/step - loss: 0.0371 - acc: 0.9889 - val_loss: 0.0243 - val_acc: 0.9928\n",
      "Epoch 14/50\n",
      "27344/27344 [==============================] - 19s 705us/step - loss: 0.0370 - acc: 0.9895 - val_loss: 0.0243 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 15/50\n",
      "27344/27344 [==============================] - 19s 704us/step - loss: 0.0347 - acc: 0.9894 - val_loss: 0.0245 - val_acc: 0.9930\n",
      "Epoch 16/50\n",
      "27344/27344 [==============================] - 19s 707us/step - loss: 0.0328 - acc: 0.9898 - val_loss: 0.0248 - val_acc: 0.9928\n",
      "Epoch 17/50\n",
      "27344/27344 [==============================] - 19s 703us/step - loss: 0.0343 - acc: 0.9899 - val_loss: 0.0244 - val_acc: 0.9928\n",
      "Epoch 00017: early stopping\n",
      "4 : Val_loss: 0.024408664985081194 , Val_acc: 0.992806905370844\n"
     ]
    }
   ],
   "source": [
    "opt = GPyOpt.methods.BayesianOptimization(f=cnn_model, \n",
    "                                          domain=params,\n",
    "                                          acquisition_type='EI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:52:51.642970Z",
     "start_time": "2018-11-12T04:40:37.871896Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23520 samples, validate on 10080 samples\n",
      "Epoch 1/50\n",
      "23520/23520 [==============================] - 20s 864us/step - loss: 0.5905 - acc: 0.8040 - val_loss: 0.0951 - val_acc: 0.9693\n",
      "Epoch 2/50\n",
      "23520/23520 [==============================] - 17s 730us/step - loss: 0.2339 - acc: 0.9251 - val_loss: 0.0794 - val_acc: 0.9749\n",
      "Epoch 3/50\n",
      "23520/23520 [==============================] - 18s 752us/step - loss: 0.1824 - acc: 0.9436 - val_loss: 0.0675 - val_acc: 0.9792\n",
      "Epoch 4/50\n",
      "23520/23520 [==============================] - 17s 739us/step - loss: 0.1571 - acc: 0.9501 - val_loss: 0.0640 - val_acc: 0.9813\n",
      "Epoch 5/50\n",
      "23520/23520 [==============================] - 17s 731us/step - loss: 0.1295 - acc: 0.9596 - val_loss: 0.0601 - val_acc: 0.9811\n",
      "Epoch 6/50\n",
      "23520/23520 [==============================] - 17s 727us/step - loss: 0.1204 - acc: 0.9625 - val_loss: 0.0450 - val_acc: 0.9849\n",
      "Epoch 7/50\n",
      "23520/23520 [==============================] - 17s 726us/step - loss: 0.1054 - acc: 0.9683 - val_loss: 0.0411 - val_acc: 0.9871\n",
      "Epoch 8/50\n",
      "23520/23520 [==============================] - 17s 729us/step - loss: 0.1043 - acc: 0.9694 - val_loss: 0.0479 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/50\n",
      "23520/23520 [==============================] - 17s 731us/step - loss: 0.0748 - acc: 0.9773 - val_loss: 0.0321 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "23520/23520 [==============================] - 17s 733us/step - loss: 0.0646 - acc: 0.9814 - val_loss: 0.0303 - val_acc: 0.9910\n",
      "Epoch 11/50\n",
      "23520/23520 [==============================] - 17s 738us/step - loss: 0.0646 - acc: 0.9801 - val_loss: 0.0300 - val_acc: 0.9911\n",
      "Epoch 12/50\n",
      "23520/23520 [==============================] - 17s 736us/step - loss: 0.0553 - acc: 0.9832 - val_loss: 0.0301 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 13/50\n",
      "23520/23520 [==============================] - 18s 744us/step - loss: 0.0556 - acc: 0.9830 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 14/50\n",
      "23520/23520 [==============================] - 17s 733us/step - loss: 0.0496 - acc: 0.9855 - val_loss: 0.0291 - val_acc: 0.9911\n",
      "Epoch 15/50\n",
      "23520/23520 [==============================] - 17s 735us/step - loss: 0.0476 - acc: 0.9855 - val_loss: 0.0283 - val_acc: 0.9919\n",
      "Epoch 16/50\n",
      "23520/23520 [==============================] - 17s 739us/step - loss: 0.0527 - acc: 0.9840 - val_loss: 0.0286 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 17/50\n",
      "23520/23520 [==============================] - 17s 743us/step - loss: 0.0476 - acc: 0.9852 - val_loss: 0.0282 - val_acc: 0.9914\n",
      "Epoch 18/50\n",
      "23520/23520 [==============================] - 17s 737us/step - loss: 0.0496 - acc: 0.9848 - val_loss: 0.0286 - val_acc: 0.9911\n",
      "Epoch 19/50\n",
      "23520/23520 [==============================] - 18s 751us/step - loss: 0.0481 - acc: 0.9848 - val_loss: 0.0284 - val_acc: 0.9912\n",
      "Epoch 20/50\n",
      "23520/23520 [==============================] - 17s 734us/step - loss: 0.0477 - acc: 0.9854 - val_loss: 0.0282 - val_acc: 0.9920\n",
      "Epoch 00020: early stopping\n",
      "5 : Val_loss: 0.028242620949712877 , Val_acc: 0.9919642857142857\n",
      "Train on 30240 samples, validate on 3360 samples\n",
      "Epoch 1/50\n",
      "30240/30240 [==============================] - 24s 784us/step - loss: 0.1591 - acc: 0.9522 - val_loss: 0.0561 - val_acc: 0.9812\n",
      "Epoch 2/50\n",
      "30240/30240 [==============================] - 20s 674us/step - loss: 0.0765 - acc: 0.9773 - val_loss: 0.0611 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 3/50\n",
      "30240/30240 [==============================] - 20s 672us/step - loss: 0.0333 - acc: 0.9895 - val_loss: 0.0264 - val_acc: 0.9929\n",
      "Epoch 4/50\n",
      "30240/30240 [==============================] - 20s 671us/step - loss: 0.0227 - acc: 0.9933 - val_loss: 0.0269 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 5/50\n",
      "30240/30240 [==============================] - 20s 672us/step - loss: 0.0160 - acc: 0.9952 - val_loss: 0.0229 - val_acc: 0.9943\n",
      "Epoch 6/50\n",
      "30240/30240 [==============================] - 20s 675us/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 7/50\n",
      "30240/30240 [==============================] - 20s 672us/step - loss: 0.0106 - acc: 0.9972 - val_loss: 0.0238 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 8/50\n",
      "30240/30240 [==============================] - 20s 673us/step - loss: 0.0076 - acc: 0.9982 - val_loss: 0.0232 - val_acc: 0.9935\n",
      "Epoch 9/50\n",
      "30240/30240 [==============================] - 20s 673us/step - loss: 0.0072 - acc: 0.9983 - val_loss: 0.0229 - val_acc: 0.9935\n",
      "Epoch 00009: early stopping\n",
      "6 : Val_loss: 0.022913726577895605 , Val_acc: 0.993452380952381\n",
      "Train on 30240 samples, validate on 3360 samples\n",
      "Epoch 1/50\n",
      "30240/30240 [==============================] - 24s 790us/step - loss: 0.1630 - acc: 0.9496 - val_loss: 0.0697 - val_acc: 0.9786\n",
      "Epoch 2/50\n",
      "30240/30240 [==============================] - 20s 676us/step - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0890 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 3/50\n",
      "30240/30240 [==============================] - 21s 681us/step - loss: 0.0358 - acc: 0.9889 - val_loss: 0.0302 - val_acc: 0.9905\n",
      "Epoch 4/50\n",
      "30240/30240 [==============================] - 21s 680us/step - loss: 0.0244 - acc: 0.9930 - val_loss: 0.0316 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 5/50\n",
      "30240/30240 [==============================] - 21s 683us/step - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0222 - val_acc: 0.9943\n",
      "Epoch 6/50\n",
      "30240/30240 [==============================] - 21s 681us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0215 - val_acc: 0.9943\n",
      "Epoch 7/50\n",
      "30240/30240 [==============================] - 21s 681us/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0223 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 8/50\n",
      "30240/30240 [==============================] - 21s 680us/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.0229 - val_acc: 0.9938\n",
      "Epoch 9/50\n",
      "30240/30240 [==============================] - 21s 681us/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0223 - val_acc: 0.9938\n",
      "Epoch 00009: early stopping\n",
      "7 : Val_loss: 0.022346920996573143 , Val_acc: 0.99375\n"
     ]
    }
   ],
   "source": [
    "opt.run_optimization(max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:32:18.986157Z",
     "start_time": "2018-11-12T05:32:18.981519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 0.0, 0.0, 256.0, 128.0, 0.1, 16.0]\n",
      "0.022346920996573143\n"
     ]
    }
   ],
   "source": [
    "x_best = opt.x_opt\n",
    "print([i for i in x_best])\n",
    "\n",
    "y_best = opt.fx_opt\n",
    "print(y_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:47:35.832634Z",
     "start_time": "2018-11-12T05:47:35.827045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'domain': 1.0, 'name': 'Dropout_0', 'type': 'continuous'},\n",
       " {'domain': 0.0, 'name': 'Dropout_1', 'type': 'continuous'},\n",
       " {'domain': 0.0, 'name': 'Dropout_2', 'type': 'continuous'},\n",
       " {'domain': 0.0, 'name': 'Dropout_3', 'type': 'continuous'},\n",
       " {'domain': 256.0, 'name': 'Dense_0', 'type': 'discrete'},\n",
       " {'domain': 128.0, 'name': 'Dense_1', 'type': 'discrete'},\n",
       " {'domain': 0.1, 'name': 'validation_split', 'type': 'continuous'},\n",
       " {'domain': 16.0, 'name': 'batch_size', 'type': 'discrete'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(x_best)):\n",
    "    params[i]['domain'] = x_best[i]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:46:53.046341Z",
     "start_time": "2018-11-12T05:46:53.041615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T06:10:58.201736Z",
     "start_time": "2018-11-12T06:10:57.887881Z"
    }
   },
   "outputs": [],
   "source": [
    "opt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
