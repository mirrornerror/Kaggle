{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggel: Digit Recognizer(MNIST)  by GPyOpt  \n",
    "Kaggle Digit recognizer: https://www.kaggle.com/c/digit-recognizer  \n",
    "GPyOpt: https://github.com/SheffieldML/GPyOpt  \n",
    "\n",
    "### Score:\n",
    "* initial_design_numdata=20, max_iter=50  score: 99.457 (515 mins: NVIDIA GTX1060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:41:17.608711Z",
     "start_time": "2018-11-14T02:41:14.615352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "seed = 123\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: MNIST from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:41:19.985863Z",
     "start_time": "2018-11-14T02:41:17.610391Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "label = train.label\n",
    "train = train.drop(['label'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train, label, test_size=0.2, shuffle=True, random_state=seed)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:41:19.994541Z",
     "start_time": "2018-11-14T02:41:19.987419Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'name': 'Dropout_0',        'type': 'continuous',  'domain': (0.0, 0.5)},\n",
    "    {'name': 'Dropout_1',        'type': 'continuous',  'domain': (0.0, 0.5)},\n",
    "    {'name': 'Dropout_2',        'type': 'continuous',  'domain': (0.0, 0.5)},\n",
    "    {'name': 'Dropout_3',        'type': 'continuous',  'domain': (0.0, 0.5)},\n",
    "    #{'name': 'BatchNorm_0',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    #{'name': 'BatchNorm_1',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    #{'name': 'BatchNorm_2',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    #{'name': 'BatchNorm_3',      'type': 'discrete',    'domain': (0, 1)},\n",
    "    {'name': 'Dense_0',          'type': 'discrete',    'domain': (128,256, 512)},\n",
    "    {'name': 'Dense_1',          'type': 'discrete',    'domain': (64,128, 256)},\n",
    "    {'name': 'validation_split', 'type': 'continuous',  'domain': (0.1, 0.3)}\n",
    "    #{'name': 'batch_size',       'type': 'discrete',    'domain': (32, 64)}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:41:20.123017Z",
     "start_time": "2018-11-14T02:41:19.995701Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "loss_list = [99]\n",
    "def cnn_model(x):\n",
    "    \n",
    "    def Param(p_name):\n",
    "        p_index = [p['name'] for p in params].index(p_name)\n",
    "        p_type = params[p_index]['type']\n",
    "        \n",
    "        if type(x) is np.ndarray:\n",
    "            if p_type == 'continuous':\n",
    "                return float(x[:, p_index])\n",
    "            else:\n",
    "                return int(x[:, p_index])\n",
    "        else: # list\n",
    "            if p_type == 'continuous':\n",
    "                return float(params[p_index]['domain'])\n",
    "            else:\n",
    "                return int(params[p_index]['domain'])\n",
    "    \n",
    "    initializer = keras.initializers.glorot_uniform(seed=seed)\n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(Reshape((28,28,1), input_shape=(784,)))\n",
    "        \n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_0'), seed=seed))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_1'), seed=seed))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(Param('Dense_0'), activation=\"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_2'), seed=seed))\n",
    "    model.add(Dense(Param('Dense_1'), activation = \"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(Param('Dropout_3'), seed=seed))\n",
    "    \n",
    "    model.add(Dense(10, activation = \"softmax\", kernel_initializer=initializer))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=0, min_lr=1e-5,verbose=1, cooldown=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=1, verbose=1, mode='auto')\n",
    "    #checkpointer = ModelCheckpoint(filepath='checkpoint'+str(cnt)+'.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    hist = model.fit(X_train, Y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=50,\n",
    "                     verbose=1,\n",
    "                     shuffle=True,\n",
    "                     validation_split=Param('validation_split'),\n",
    "                     callbacks=[reduce_lr, early_stopping])\n",
    "    \n",
    "    #loss, acc = model.evaluate(X_test, Y_test, batch_size=Param('batch_size') , verbose=0)\n",
    "    loss = hist.history['val_loss'][-1]\n",
    "    acc = hist.history['val_acc'][-1]\n",
    "    \n",
    "    global cnt\n",
    "    print(cnt, ': Test_loss:', loss, ', Test_acc:', acc)\n",
    "    print('Model: ', model, '\\n\\n')\n",
    "    cnt += 1\n",
    "    \n",
    "    return loss, acc, model, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:41:20.131465Z",
     "start_time": "2018-11-14T02:41:20.124359Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = np.atleast_2d(x)\n",
    "    fs = np.zeros((x.shape[0],1))\n",
    "    for i in range(x.shape[0]):\n",
    "        loss, acc, model, hist = cnn_model(x)\n",
    "        fs[i] += np.log(acc)*(-1)\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:43:22.840936Z",
     "start_time": "2018-11-14T02:41:20.132774Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25280 samples, validate on 8320 samples\n",
      "Epoch 1/50\n",
      "25280/25280 [==============================] - 11s 449us/step - loss: 0.2512 - acc: 0.9192 - val_loss: 0.0758 - val_acc: 0.9749\n",
      "Epoch 2/50\n",
      "25280/25280 [==============================] - 9s 360us/step - loss: 0.0992 - acc: 0.9697 - val_loss: 0.0540 - val_acc: 0.9825\n",
      "Epoch 3/50\n",
      "25280/25280 [==============================] - 9s 362us/step - loss: 0.0779 - acc: 0.9763 - val_loss: 0.0531 - val_acc: 0.9838\n",
      "Epoch 4/50\n",
      "25280/25280 [==============================] - 10s 380us/step - loss: 0.0696 - acc: 0.9788 - val_loss: 0.0495 - val_acc: 0.9846\n",
      "Epoch 5/50\n",
      "25280/25280 [==============================] - 9s 362us/step - loss: 0.0639 - acc: 0.9803 - val_loss: 0.0462 - val_acc: 0.9862\n",
      "Epoch 6/50\n",
      "25280/25280 [==============================] - 9s 361us/step - loss: 0.0521 - acc: 0.9839 - val_loss: 0.0520 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00006: early stopping\n",
      "0 : Test_loss: 0.05201436398112072 , Test_acc: 0.9846153846153847\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8c23ce4898> \n",
      "\n",
      "\n",
      "Train on 29013 samples, validate on 4587 samples\n",
      "Epoch 1/50\n",
      "29013/29013 [==============================] - 10s 361us/step - loss: 0.2128 - acc: 0.9362 - val_loss: 0.0940 - val_acc: 0.9714\n",
      "Epoch 2/50\n",
      "29013/29013 [==============================] - 10s 330us/step - loss: 0.0860 - acc: 0.9744 - val_loss: 0.0581 - val_acc: 0.9808\n",
      "Epoch 3/50\n",
      "29013/29013 [==============================] - 9s 324us/step - loss: 0.0667 - acc: 0.9793 - val_loss: 0.0414 - val_acc: 0.9869\n",
      "Epoch 4/50\n",
      "29013/29013 [==============================] - 9s 327us/step - loss: 0.0573 - acc: 0.9826 - val_loss: 0.0529 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00004: early stopping\n",
      "1 : Test_loss: 0.05294726197210881 , Test_acc: 0.9827774144320907\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8bfc183710> \n",
      "\n",
      "\n",
      "Train on 29060 samples, validate on 4540 samples\n",
      "Epoch 1/50\n",
      "29060/29060 [==============================] - 12s 409us/step - loss: 0.2071 - acc: 0.9349 - val_loss: 0.0962 - val_acc: 0.9705\n",
      "Epoch 2/50\n",
      "29060/29060 [==============================] - 10s 354us/step - loss: 0.0903 - acc: 0.9725 - val_loss: 0.1082 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00002: early stopping\n",
      "2 : Test_loss: 0.1081506973468916 , Test_acc: 0.964977973568282\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8a6e007b38> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = GPyOpt.methods.BayesianOptimization(f=f, \n",
    "                                          domain=params,\n",
    "                                          initial_design_numdata=3,\n",
    "                                          model_type='GP_MCMC',\n",
    "                                          acquisition_type='EI_MCMC',\n",
    "                                          exact_feval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:47:47.706683Z",
     "start_time": "2018-11-14T02:43:22.842252Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters GP_regression.rbf\n",
      "reconstraining parameters GP_regression.Gaussian_noise.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23520 samples, validate on 10080 samples\n",
      "Epoch 1/50\n",
      "23520/23520 [==============================] - 10s 428us/step - loss: 0.2555 - acc: 0.9213 - val_loss: 0.0764 - val_acc: 0.9763\n",
      "Epoch 2/50\n",
      "23520/23520 [==============================] - 9s 369us/step - loss: 0.1039 - acc: 0.9677 - val_loss: 0.0913 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00002: early stopping\n",
      "0 : Test_loss: 0.0912989710604528 , Test_acc: 0.9737103174603174\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8a67257f98> \n",
      "\n",
      "\n",
      "Train on 23520 samples, validate on 10080 samples\n",
      "Epoch 1/50\n",
      "23520/23520 [==============================] - 10s 440us/step - loss: 0.2375 - acc: 0.9249 - val_loss: 0.1067 - val_acc: 0.9651\n",
      "Epoch 2/50\n",
      "23520/23520 [==============================] - 9s 381us/step - loss: 0.1009 - acc: 0.9680 - val_loss: 0.0724 - val_acc: 0.9770\n",
      "Epoch 3/50\n",
      "23520/23520 [==============================] - 9s 380us/step - loss: 0.0800 - acc: 0.9748 - val_loss: 0.0472 - val_acc: 0.9850\n",
      "Epoch 4/50\n",
      "23520/23520 [==============================] - 9s 383us/step - loss: 0.0592 - acc: 0.9811 - val_loss: 0.0643 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00004: early stopping\n",
      "1 : Test_loss: 0.06432711085515275 , Test_acc: 0.9808531746031746\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8a481109b0> \n",
      "\n",
      "\n",
      "Train on 25649 samples, validate on 7951 samples\n",
      "Epoch 1/50\n",
      "25649/25649 [==============================] - 11s 442us/step - loss: 0.3157 - acc: 0.8992 - val_loss: 0.1025 - val_acc: 0.9699\n",
      "Epoch 2/50\n",
      "25649/25649 [==============================] - 10s 377us/step - loss: 0.1214 - acc: 0.9611 - val_loss: 0.0943 - val_acc: 0.9699\n",
      "Epoch 3/50\n",
      "25649/25649 [==============================] - 10s 377us/step - loss: 0.0966 - acc: 0.9711 - val_loss: 0.0546 - val_acc: 0.9829\n",
      "Epoch 4/50\n",
      "25649/25649 [==============================] - 10s 376us/step - loss: 0.0823 - acc: 0.9740 - val_loss: 0.0630 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00004: early stopping\n",
      "2 : Test_loss: 0.06295149293208689 , Test_acc: 0.9811344484970443\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8a4147dfd0> \n",
      "\n",
      "\n",
      "Train on 24287 samples, validate on 9313 samples\n",
      "Epoch 1/50\n",
      "24287/24287 [==============================] - 11s 454us/step - loss: 0.2752 - acc: 0.9132 - val_loss: 0.0677 - val_acc: 0.9785\n",
      "Epoch 2/50\n",
      "24287/24287 [==============================] - 9s 385us/step - loss: 0.1068 - acc: 0.9664 - val_loss: 0.0978 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00002: early stopping\n",
      "3 : Test_loss: 0.09784033206652205 , Test_acc: 0.9705787608718995\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8a3b8cf630> \n",
      "\n",
      "\n",
      "Train on 25455 samples, validate on 8145 samples\n",
      "Epoch 1/50\n",
      "25455/25455 [==============================] - 12s 453us/step - loss: 0.2396 - acc: 0.9251 - val_loss: 0.0760 - val_acc: 0.9779\n",
      "Epoch 2/50\n",
      "25455/25455 [==============================] - 10s 382us/step - loss: 0.0979 - acc: 0.9698 - val_loss: 0.0552 - val_acc: 0.9832\n",
      "Epoch 3/50\n",
      "25455/25455 [==============================] - 10s 383us/step - loss: 0.0739 - acc: 0.9766 - val_loss: 0.0503 - val_acc: 0.9849\n",
      "Epoch 4/50\n",
      "25455/25455 [==============================] - 10s 383us/step - loss: 0.0653 - acc: 0.9804 - val_loss: 0.0461 - val_acc: 0.9861\n",
      "Epoch 5/50\n",
      "25455/25455 [==============================] - 10s 381us/step - loss: 0.0572 - acc: 0.9817 - val_loss: 0.0424 - val_acc: 0.9878\n",
      "Epoch 6/50\n",
      "25455/25455 [==============================] - 10s 382us/step - loss: 0.0552 - acc: 0.9823 - val_loss: 0.0411 - val_acc: 0.9871\n",
      "Epoch 7/50\n",
      "25455/25455 [==============================] - 10s 386us/step - loss: 0.0507 - acc: 0.9840 - val_loss: 0.0440 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 00007: early stopping\n",
      "4 : Test_loss: 0.044025198285218656 , Test_acc: 0.9868631062001227\n",
      "Model:  <keras.engine.sequential.Sequential object at 0x7f8a3a425048> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "opt.run_optimization(max_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T02:47:47.713021Z",
     "start_time": "2018-11-14T02:47:47.708286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24926097013931897, 0.4878302952129035, 0.17440831641662402, 0.18874847856231725, 512.0, 256.0, 0.242406918078481]\n",
      "0.013223946026999119\n"
     ]
    }
   ],
   "source": [
    "x_best = opt.x_opt\n",
    "print([i for i in x_best])\n",
    "\n",
    "y_best = opt.fx_opt\n",
    "print(y_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the best hyperparameters for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:36:25.188438Z",
     "start_time": "2018-11-13T23:35:47.021Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = params\n",
    "p_type = [p['type'] for p in best_params]\n",
    "\n",
    "for i in range(len(x_best)):\n",
    "    best_params[i]['domain'] = x_best[i]\n",
    "    if p_type[i] == 'discrete':\n",
    "        best_params[i]['domain'] = int(best_params[i]['domain'])\n",
    "        \n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:36:25.189662Z",
     "start_time": "2018-11-13T23:35:47.022Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loss, val_acc, model, hist = cnn_model(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for the submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:36:25.190662Z",
     "start_time": "2018-11-13T23:35:47.024Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../test.csv')\n",
    "test_index = test.index\n",
    "test = test.values.astype('float32') / 255.0\n",
    "\n",
    "pred = model.predict(test, verbose=1)\n",
    "result = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission file output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:36:25.191716Z",
     "start_time": "2018-11-13T23:35:47.025Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': test_index+1, 'Label': result})\n",
    "submission.to_csv('gpyopt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approximate accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:36:25.192927Z",
     "start_time": "2018-11-13T23:35:47.027Z"
    }
   },
   "outputs": [],
   "source": [
    "# comparison with the best score\n",
    "prev_cnn = pd.read_csv('../cnn_submission.csv', index_col=0)\n",
    "res = pd.read_csv('gpyopt_submission.csv', index_col=0)\n",
    "diff_num = np.sum(prev_cnn.Label.values != res.Label.values)\n",
    "acc = (len(res) - diff_num) / len(res) #* 0.998276\n",
    "print('Approx. accuracy: {0:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T23:36:25.193769Z",
     "start_time": "2018-11-13T23:35:47.029Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['val_acc'], label='val_loss')\n",
    "plt.plot(hist.history['acc'], label='loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
