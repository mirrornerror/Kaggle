{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggel: Digit Recognizer(MNIST)  by Hyperopt  \n",
    "Kaggle Digit recognizer: https://www.kaggle.com/c/digit-recognizer  \n",
    "Hyperopt: https://github.com/hyperopt/hyperopt  \n",
    "\n",
    "### Score:\n",
    "* max_evals= 10, score: 0.99128 ( 25 mins: NVIDIA GTX1060)\n",
    "* max_evals= 20, score: 0.99257 ( 49 mins: NVIDIA GTX1060)\n",
    "* max_evals=100, score: 0.99185 (372 mins: NVIDIA GTX1060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T12:06:16.387847Z",
     "start_time": "2018-11-14T12:06:16.343967Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from hyperopt import hp, fmin, rand, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# fix random seed\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "seed = 123\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: MNIST from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T12:06:18.633532Z",
     "start_time": "2018-11-14T12:06:16.388964Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "label = train.label\n",
    "train = train.drop(['label'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train, label, test_size=0.1, random_state=seed)\n",
    "X_train = X_train.values.astype('float32') / 255.0\n",
    "X_test = X_test.values.astype('float32') / 255.0\n",
    "\n",
    "nb_classes = 10 \n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T12:06:18.639543Z",
     "start_time": "2018-11-14T12:06:18.634956Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Dropout_0':        hp.uniform('Dropout_0', 0.0, 0.5),\n",
    "    'Dropout_1':        hp.uniform('Dropout_1', 0.0, 0.5),\n",
    "    'Dropout_2':        hp.uniform('Dropout_2', 0.0, 0.5),\n",
    "    'Dropout_3':        hp.uniform('Dropout_3', 0.0, 0.5),\n",
    "    'Dense_0':          hp.choice('Dense_0', [128, 256, 512]),\n",
    "    'Dense_1':          hp.choice('Dense_1', [64, 128, 256])\n",
    "    #'validation_split': hp.uniform('validation_split', 0.1, 0.3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T12:06:18.726990Z",
     "start_time": "2018-11-14T12:06:18.640969Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt = 1\n",
    "def cnn_model(params):\n",
    "    \n",
    "    initializer = keras.initializers.glorot_uniform(seed=seed)\n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(Reshape((28,28,1), input_shape=(784,)))\n",
    "    \n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_0'], seed=seed))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_1'], seed=seed))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(params['Dense_0'], activation=\"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_2'], seed=seed))\n",
    "    model.add(Dense(params['Dense_1'], activation = \"relu\", kernel_initializer=initializer))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['Dropout_3'], seed=seed))\n",
    "    \n",
    "    model.add(Dense(10, activation = \"softmax\", kernel_initializer=initializer))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5,verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    hist = model.fit(X_train, Y_train,\n",
    "                     batch_size=32,\n",
    "                     epochs=50,\n",
    "                     verbose=1,\n",
    "                     #validation_split=params['validation_split'],\n",
    "                     validation_data=(X_test, Y_test),\n",
    "                     callbacks=[reduce_lr, early_stopping])\n",
    "    \n",
    "    #score, acc = model.evaluate(X_test, Y_test, batch_size=params['batch_size'] , verbose=0)\n",
    "    loss = hist.history['val_loss'][-1]\n",
    "    acc = hist.history['val_acc'][-1]\n",
    "    \n",
    "    global cnt\n",
    "    print(cnt, ': Val_loss:', loss, ', Val_acc:', acc, '\\n\\n')\n",
    "    cnt += 1\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the Best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:07.945677Z",
     "start_time": "2018-11-14T12:06:18.728424Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 19s 492us/step - loss: 0.2098 - acc: 0.9361 - val_loss: 0.1139 - val_acc: 0.9626\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 15s 406us/step - loss: 0.0824 - acc: 0.9747 - val_loss: 0.0507 - val_acc: 0.9836\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 15s 403us/step - loss: 0.0712 - acc: 0.9785 - val_loss: 0.0611 - val_acc: 0.9826\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0561 - acc: 0.9833 - val_loss: 0.0358 - val_acc: 0.9888\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0548 - acc: 0.9832 - val_loss: 0.0361 - val_acc: 0.9890\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0455 - acc: 0.9867 - val_loss: 0.0259 - val_acc: 0.9910\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0379 - acc: 0.9888 - val_loss: 0.0459 - val_acc: 0.9874\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 15s 403us/step - loss: 0.0362 - acc: 0.9896 - val_loss: 0.0348 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0181 - val_acc: 0.9955\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.0161 - val_acc: 0.9952\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.0167 - val_acc: 0.9940\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 15s 405us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0210 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 15s 403us/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0164 - val_acc: 0.9936\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0099 - acc: 0.9968 - val_loss: 0.0143 - val_acc: 0.9952\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0174 - val_acc: 0.9952\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0182 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 15s 405us/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0158 - val_acc: 0.9952\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 15s 405us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0174 - val_acc: 0.9952\n",
      "Epoch 00019: early stopping\n",
      "1 : Val_loss: 0.017391850375036787 , Val_acc: 0.9952380952380953 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 18s 467us/step - loss: 0.2078 - acc: 0.9366 - val_loss: 0.0875 - val_acc: 0.9717\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 14s 378us/step - loss: 0.0836 - acc: 0.9748 - val_loss: 0.0844 - val_acc: 0.9731\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 15s 387us/step - loss: 0.0614 - acc: 0.9823 - val_loss: 0.0524 - val_acc: 0.9819\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 15s 388us/step - loss: 0.0585 - acc: 0.9821 - val_loss: 0.0687 - val_acc: 0.9793\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 15s 384us/step - loss: 0.0488 - acc: 0.9852 - val_loss: 0.0333 - val_acc: 0.9893\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 14s 383us/step - loss: 0.0440 - acc: 0.9867 - val_loss: 0.0695 - val_acc: 0.9810\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0420 - acc: 0.9872 - val_loss: 0.0239 - val_acc: 0.9933\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0317 - acc: 0.9901 - val_loss: 0.0276 - val_acc: 0.9914\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0320 - acc: 0.9908 - val_loss: 0.0248 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0200 - acc: 0.9941 - val_loss: 0.0190 - val_acc: 0.9948\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 15s 384us/step - loss: 0.0143 - acc: 0.9957 - val_loss: 0.0237 - val_acc: 0.9936\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0181 - val_acc: 0.9955\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 15s 387us/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0228 - val_acc: 0.9926\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0157 - val_acc: 0.9960\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 15s 384us/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0225 - val_acc: 0.9950\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 15s 384us/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0260 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 15s 387us/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0157 - val_acc: 0.9957\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 15s 385us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0178 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 15s 384us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0183 - val_acc: 0.9952\n",
      "Epoch 00019: early stopping\n",
      "2 : Val_loss: 0.01831064450714101 , Val_acc: 0.9952380952380953 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 20s 516us/step - loss: 0.2231 - acc: 0.9315 - val_loss: 0.0515 - val_acc: 0.9810\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 16s 421us/step - loss: 0.0917 - acc: 0.9728 - val_loss: 0.0486 - val_acc: 0.9855\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 16s 419us/step - loss: 0.0719 - acc: 0.9782 - val_loss: 0.0487 - val_acc: 0.9864\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 16s 420us/step - loss: 0.0620 - acc: 0.9822 - val_loss: 0.0440 - val_acc: 0.9879\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 16s 420us/step - loss: 0.0527 - acc: 0.9837 - val_loss: 0.0403 - val_acc: 0.9874\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 16s 420us/step - loss: 0.0531 - acc: 0.9838 - val_loss: 0.0258 - val_acc: 0.9921\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 16s 421us/step - loss: 0.0426 - acc: 0.9869 - val_loss: 0.0253 - val_acc: 0.9926\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0407 - acc: 0.9877 - val_loss: 0.0323 - val_acc: 0.9902\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 16s 422us/step - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0229 - val_acc: 0.9921\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 16s 420us/step - loss: 0.0358 - acc: 0.9896 - val_loss: 0.0187 - val_acc: 0.9950\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 16s 419us/step - loss: 0.0313 - acc: 0.9903 - val_loss: 0.0237 - val_acc: 0.9933\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 16s 417us/step - loss: 0.0308 - acc: 0.9915 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 16s 419us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0195 - val_acc: 0.9955\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 16s 415us/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.0192 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 16s 415us/step - loss: 0.0119 - acc: 0.9966 - val_loss: 0.0159 - val_acc: 0.9962\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 16s 413us/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0215 - val_acc: 0.9957\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 16s 414us/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0204 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 16s 417us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0206 - val_acc: 0.9960\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 16s 415us/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0176 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 16s 414us/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0181 - val_acc: 0.9967\n",
      "Epoch 00020: early stopping\n",
      "3 : Val_loss: 0.018098909668094295 , Val_acc: 0.9966666666666667 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 20s 530us/step - loss: 0.1731 - acc: 0.9462 - val_loss: 0.0772 - val_acc: 0.9786\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 16s 419us/step - loss: 0.0765 - acc: 0.9770 - val_loss: 0.0488 - val_acc: 0.9840\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 16s 420us/step - loss: 0.0591 - acc: 0.9818 - val_loss: 0.0900 - val_acc: 0.9762\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 16s 423us/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0424 - val_acc: 0.9876\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 16s 424us/step - loss: 0.0405 - acc: 0.9877 - val_loss: 0.0432 - val_acc: 0.9883\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 16s 424us/step - loss: 0.0396 - acc: 0.9883 - val_loss: 0.0445 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0235 - acc: 0.9928 - val_loss: 0.0235 - val_acc: 0.9933\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0207 - acc: 0.9938 - val_loss: 0.0222 - val_acc: 0.9940\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0168 - acc: 0.9951 - val_loss: 0.0241 - val_acc: 0.9931\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 16s 430us/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.0257 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0185 - val_acc: 0.9952\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 16s 427us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.0231 - val_acc: 0.9936\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 16s 426us/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0192 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0206 - val_acc: 0.9948\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0182 - val_acc: 0.9962\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 16s 426us/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0181 - val_acc: 0.9962\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 16s 423us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0197 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0184 - val_acc: 0.9957\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 16s 425us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0191 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 16s 424us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0190 - val_acc: 0.9960\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 16s 426us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0182 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 00021: early stopping\n",
      "4 : Val_loss: 0.018150022763574747 , Val_acc: 0.9959523809523809 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 18s 482us/step - loss: 0.2087 - acc: 0.9366 - val_loss: 0.0519 - val_acc: 0.9852\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 14s 379us/step - loss: 0.0824 - acc: 0.9760 - val_loss: 0.0542 - val_acc: 0.9852\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 14s 380us/step - loss: 0.0674 - acc: 0.9798 - val_loss: 0.0607 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 14s 380us/step - loss: 0.0468 - acc: 0.9856 - val_loss: 0.0341 - val_acc: 0.9895\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 14s 382us/step - loss: 0.0434 - acc: 0.9872 - val_loss: 0.0264 - val_acc: 0.9902\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 14s 379us/step - loss: 0.0350 - acc: 0.9893 - val_loss: 0.0301 - val_acc: 0.9910\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 14s 379us/step - loss: 0.0360 - acc: 0.9887 - val_loss: 0.0253 - val_acc: 0.9926\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 14s 379us/step - loss: 0.0304 - acc: 0.9908 - val_loss: 0.0301 - val_acc: 0.9900\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 14s 378us/step - loss: 0.0274 - acc: 0.9916 - val_loss: 0.0330 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 14s 378us/step - loss: 0.0205 - acc: 0.9938 - val_loss: 0.0177 - val_acc: 0.9952\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 14s 380us/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0174 - val_acc: 0.9952\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 14s 377us/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.0183 - val_acc: 0.9945\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 14s 377us/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 14s 377us/step - loss: 0.0124 - acc: 0.9959 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 14s 380us/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.0163 - val_acc: 0.9962\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 14s 377us/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.0161 - val_acc: 0.9964\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 14s 379us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0158 - val_acc: 0.9962\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 14s 380us/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0161 - val_acc: 0.9952\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 14s 379us/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0174 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 15s 384us/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0164 - val_acc: 0.9962\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 14s 377us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 14s 374us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9955\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 14s 374us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0167 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 24/50\n",
      "37800/37800 [==============================] - 14s 374us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0162 - val_acc: 0.9962\n",
      "Epoch 25/50\n",
      "37800/37800 [==============================] - 14s 373us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9967\n",
      "Epoch 26/50\n",
      "37800/37800 [==============================] - 14s 373us/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0157 - val_acc: 0.9964\n",
      "Epoch 27/50\n",
      "37800/37800 [==============================] - 14s 373us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0173 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 28/50\n",
      "37800/37800 [==============================] - 14s 373us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0162 - val_acc: 0.9960\n",
      "Epoch 29/50\n",
      "37800/37800 [==============================] - 14s 373us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0161 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 30/50\n",
      "37800/37800 [==============================] - 14s 372us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "Epoch 00030: early stopping\n",
      "5 : Val_loss: 0.01559568798201889 , Val_acc: 0.9964285714285714 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 19s 496us/step - loss: 0.1824 - acc: 0.9453 - val_loss: 0.0561 - val_acc: 0.9817\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 15s 394us/step - loss: 0.0791 - acc: 0.9749 - val_loss: 0.0663 - val_acc: 0.9795\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 15s 395us/step - loss: 0.0607 - acc: 0.9816 - val_loss: 0.0321 - val_acc: 0.9912\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0524 - acc: 0.9845 - val_loss: 0.0309 - val_acc: 0.9926\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0417 - acc: 0.9872 - val_loss: 0.0594 - val_acc: 0.9800\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0402 - acc: 0.9878 - val_loss: 0.0408 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0257 - acc: 0.9923 - val_loss: 0.0235 - val_acc: 0.9933\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 15s 398us/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.0269 - val_acc: 0.9921\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.0220 - val_acc: 0.9943\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 15s 400us/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0254 - val_acc: 0.9931\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0236 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 15s 400us/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0204 - val_acc: 0.9945\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 15s 399us/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0170 - val_acc: 0.9960\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 15s 392us/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0185 - val_acc: 0.9950\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 15s 392us/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0184 - val_acc: 0.9952\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 15s 396us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0171 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 15s 397us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0167 - val_acc: 0.9962\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 15s 398us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0172 - val_acc: 0.9964\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 15s 398us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0187 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 15s 400us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0180 - val_acc: 0.9955\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 15s 398us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0181 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 15s 399us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0184 - val_acc: 0.9955\n",
      "Epoch 00023: early stopping\n",
      "6 : Val_loss: 0.01836867915791767 , Val_acc: 0.9954761904761905 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 21s 543us/step - loss: 0.1796 - acc: 0.9441 - val_loss: 0.0897 - val_acc: 0.9690\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 16s 434us/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0495 - val_acc: 0.9836\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 16s 434us/step - loss: 0.0601 - acc: 0.9812 - val_loss: 0.0446 - val_acc: 0.9874\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 16s 435us/step - loss: 0.0536 - acc: 0.9836 - val_loss: 0.0385 - val_acc: 0.9881\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0464 - acc: 0.9856 - val_loss: 0.0355 - val_acc: 0.9893\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 17s 437us/step - loss: 0.0418 - acc: 0.9869 - val_loss: 0.0330 - val_acc: 0.9900\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0394 - acc: 0.9876 - val_loss: 0.0308 - val_acc: 0.9898\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0251 - val_acc: 0.9912\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0332 - acc: 0.9897 - val_loss: 0.0219 - val_acc: 0.9936\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 16s 431us/step - loss: 0.0303 - acc: 0.9906 - val_loss: 0.0274 - val_acc: 0.9933\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 16s 431us/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.0258 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 16s 434us/step - loss: 0.0173 - acc: 0.9947 - val_loss: 0.0220 - val_acc: 0.9938\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.0254 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.0181 - val_acc: 0.9957\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0158 - val_acc: 0.9952\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 17s 446us/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0203 - val_acc: 0.9936\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 16s 430us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0158 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0153 - val_acc: 0.9957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0163 - val_acc: 0.9957\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0177 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0167 - val_acc: 0.9950\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0165 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0160 - val_acc: 0.9955\n",
      "Epoch 00023: early stopping\n",
      "7 : Val_loss: 0.01604700237555551 , Val_acc: 0.9954761904761905 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 21s 544us/step - loss: 0.2206 - acc: 0.9304 - val_loss: 0.0729 - val_acc: 0.9764\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 16s 431us/step - loss: 0.0932 - acc: 0.9708 - val_loss: 0.0652 - val_acc: 0.9800\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 16s 431us/step - loss: 0.0729 - acc: 0.9782 - val_loss: 0.0628 - val_acc: 0.9817\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0598 - acc: 0.9814 - val_loss: 0.0316 - val_acc: 0.9907\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0585 - acc: 0.9820 - val_loss: 0.0320 - val_acc: 0.9900\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0540 - acc: 0.9835 - val_loss: 0.0308 - val_acc: 0.9900\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0434 - acc: 0.9871 - val_loss: 0.0274 - val_acc: 0.9910\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0387 - acc: 0.9883 - val_loss: 0.0420 - val_acc: 0.9852\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0384 - acc: 0.9876 - val_loss: 0.0270 - val_acc: 0.9921\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 16s 428us/step - loss: 0.0348 - acc: 0.9897 - val_loss: 0.0252 - val_acc: 0.9938\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.0248 - val_acc: 0.9926\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 16s 429us/step - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9900\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0255 - acc: 0.9925 - val_loss: 0.0223 - val_acc: 0.9929\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0253 - acc: 0.9922 - val_loss: 0.0200 - val_acc: 0.9926\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 16s 432us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0327 - val_acc: 0.9907\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 16s 434us/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0223 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 16s 435us/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 16s 434us/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0211 - val_acc: 0.9948\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 16s 436us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0184 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0158 - val_acc: 0.9952\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0159 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 22/50\n",
      "37800/37800 [==============================] - 16s 433us/step - loss: 0.0058 - acc: 0.9979 - val_loss: 0.0156 - val_acc: 0.9962\n",
      "Epoch 00022: early stopping\n",
      "8 : Val_loss: 0.01561672602811346 , Val_acc: 0.9961904761904762 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 21s 553us/step - loss: 0.1781 - acc: 0.9452 - val_loss: 0.0608 - val_acc: 0.9814\n",
      "Epoch 2/50\n",
      "37800/37800 [==============================] - 17s 440us/step - loss: 0.0820 - acc: 0.9744 - val_loss: 0.0448 - val_acc: 0.9886\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 17s 440us/step - loss: 0.0641 - acc: 0.9801 - val_loss: 0.0412 - val_acc: 0.9888\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 17s 441us/step - loss: 0.0518 - acc: 0.9841 - val_loss: 0.0632 - val_acc: 0.9790\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 17s 442us/step - loss: 0.0475 - acc: 0.9851 - val_loss: 0.0543 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 17s 443us/step - loss: 0.0305 - acc: 0.9907 - val_loss: 0.0193 - val_acc: 0.9948\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 17s 441us/step - loss: 0.0250 - acc: 0.9921 - val_loss: 0.0292 - val_acc: 0.9912\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 17s 439us/step - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0268 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 17s 440us/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0228 - val_acc: 0.9936\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 17s 440us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 17s 442us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0178 - val_acc: 0.9952\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 17s 443us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0170 - val_acc: 0.9950\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 17s 441us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0186 - val_acc: 0.9945\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 17s 441us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0172 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 17s 441us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0171 - val_acc: 0.9955\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 17s 442us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0161 - val_acc: 0.9955\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 17s 444us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0184 - val_acc: 0.9955\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 17s 440us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0192 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 17s 441us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0192 - val_acc: 0.9960\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 17s 439us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0191 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 17s 440us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0190 - val_acc: 0.9957\n",
      "Epoch 00021: early stopping\n",
      "9 : Val_loss: 0.01900037550876992 , Val_acc: 0.9957142857142857 \n",
      "\n",
      "\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/50\n",
      "37800/37800 [==============================] - 20s 530us/step - loss: 0.2490 - acc: 0.9223 - val_loss: 0.0484 - val_acc: 0.9855\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0949 - acc: 0.9712 - val_loss: 0.0688 - val_acc: 0.9793\n",
      "Epoch 3/50\n",
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0786 - acc: 0.9763 - val_loss: 0.0402 - val_acc: 0.9869\n",
      "Epoch 4/50\n",
      "37800/37800 [==============================] - 16s 421us/step - loss: 0.0667 - acc: 0.9797 - val_loss: 0.0375 - val_acc: 0.9876\n",
      "Epoch 5/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0582 - acc: 0.9823 - val_loss: 0.0311 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0518 - acc: 0.9838 - val_loss: 0.0352 - val_acc: 0.9888\n",
      "Epoch 7/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0486 - acc: 0.9854 - val_loss: 0.0392 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/50\n",
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0341 - acc: 0.9897 - val_loss: 0.0274 - val_acc: 0.9919\n",
      "Epoch 9/50\n",
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0196 - val_acc: 0.9943\n",
      "Epoch 10/50\n",
      "37800/37800 [==============================] - 15s 409us/step - loss: 0.0263 - acc: 0.9921 - val_loss: 0.0214 - val_acc: 0.9940\n",
      "Epoch 11/50\n",
      "37800/37800 [==============================] - 15s 409us/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0226 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0197 - val_acc: 0.9940\n",
      "Epoch 13/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0167 - acc: 0.9951 - val_loss: 0.0162 - val_acc: 0.9960\n",
      "Epoch 14/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0163 - val_acc: 0.9948\n",
      "Epoch 15/50\n",
      "37800/37800 [==============================] - 15s 407us/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0189 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/50\n",
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0140 - acc: 0.9958 - val_loss: 0.0149 - val_acc: 0.9957\n",
      "Epoch 17/50\n",
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0154 - val_acc: 0.9950\n",
      "Epoch 18/50\n",
      "37800/37800 [==============================] - 15s 408us/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0161 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 19/50\n",
      "37800/37800 [==============================] - 15s 404us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0166 - val_acc: 0.9957\n",
      "Epoch 20/50\n",
      "37800/37800 [==============================] - 15s 406us/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0149 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 21/50\n",
      "37800/37800 [==============================] - 16s 410us/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.0150 - val_acc: 0.9962\n",
      "Epoch 00021: early stopping\n",
      "10 : Val_loss: 0.01501453281791501 , Val_acc: 0.9961904761904762 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Dense_0': 2,\n",
       " 'Dense_1': 2,\n",
       " 'Dropout_0': 0.01183659359352257,\n",
       " 'Dropout_1': 0.41822117909744994,\n",
       " 'Dropout_2': 0.38154401500871815,\n",
       " 'Dropout_3': 0.4962590536997257}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=cnn_model, \n",
    "            space=params, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=10, \n",
    "            trials=trials,\n",
    "            verbose=1,\n",
    "            rstate=np.random.RandomState(seed))\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Best Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:07.953521Z",
     "start_time": "2018-11-14T13:04:07.946870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense_0': 512,\n",
       " 'Dense_1': 256,\n",
       " 'Dropout_0': 0.01183659359352257,\n",
       " 'Dropout_1': 0.41822117909744994,\n",
       " 'Dropout_2': 0.38154401500871815,\n",
       " 'Dropout_3': 0.4962590536997257}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_eval(params, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:07.971543Z",
     "start_time": "2018-11-14T13:04:07.955214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': -0.9966666666666667,\n",
       " 'model': <keras.engine.sequential.Sequential at 0x7f754ccb0f60>,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T05:18:12.461129Z",
     "start_time": "2018-11-10T05:18:12.454484Z"
    }
   },
   "source": [
    "## The Best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:07.977584Z",
     "start_time": "2018-11-14T13:04:07.972946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f754ccb0f60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = trials.best_trial['result']['model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:14.479661Z",
     "start_time": "2018-11-14T13:04:07.978990Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../test.csv')\n",
    "test_index = test.index\n",
    "test = test.values.astype('float32') / 255.0\n",
    "\n",
    "pred = best_model.predict(test)\n",
    "result = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission csv file output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:14.537107Z",
     "start_time": "2018-11-14T13:04:14.480899Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': test_index+1, 'Label': result})\n",
    "submission.to_csv('hyperopt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:04:14.553772Z",
     "start_time": "2018-11-14T13:04:14.538666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. accuracy: 0.99481\n"
     ]
    }
   ],
   "source": [
    "prev_cnn = pd.read_csv('../cnn_submission.csv', index_col=0)\n",
    "res = pd.read_csv('hyperopt_submission.csv', index_col=0)\n",
    "diff_num = np.sum(prev_cnn.Label.values != res.Label.values)\n",
    "acc = (len(res) - diff_num) / len(res) * 0.99852\n",
    "print('Approx. accuracy: {0:.5f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx. accuracy: 0.99364  \n",
    "Approx. accuracy: 0.99368  \n",
    "Approx. accuracy: 0.99442 : validation_data(X_test, Y_test) split:0.2\n",
    "Approx. accuracy: 0.99481 : validation_data(X_test, Y_test) split:0.1, score:0.99528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T13:11:53.375970Z",
     "start_time": "2018-11-14T13:11:47.968758Z"
    }
   },
   "outputs": [],
   "source": [
    "#best_model.save('hyperopt_model_99528.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/bcb948a148c98d1ecdb82f3663067822"
  },
  "gist": {
   "data": {
    "description": "Kaggle: Digital Recognizer(MNIST) by Hyperopt",
    "public": true
   },
   "id": "bcb948a148c98d1ecdb82f3663067822"
  },
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
